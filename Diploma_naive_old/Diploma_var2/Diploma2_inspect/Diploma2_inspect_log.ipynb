{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88dddc8-1b72-4fc1-8132-801809339895",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html\n",
    "\n",
    "При решении задач регрессии используются именно регрессоры. Из хороших классических алгоритмов - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07e255-99e8-450a-bfd3-94d142208a5c",
   "metadata": {},
   "source": [
    "В этой тетради мы будем исследовать наш df  на предмет пропусков, нулевых значений выбросов и занчений ,которые противоречат физике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78edf10-c1a5-4d7b-9791-8dbecc50e736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импортируем в проект требуемые библиотеки\n",
    "\n",
    "import pandas as pd # библиотека для обработки и анализа данных\n",
    "import numpy as np\n",
    "import seaborn as sns # библиотека для создания статистических графиков\n",
    "import random #  генераторатор случайных чисел и данных\n",
    "import os # библиотека функций для работы с операционной системой.\n",
    "\n",
    "from sklearn. preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "import ydata_profiling # pandas_profiling!!!! отменяется c 1-го апреля 2023 г\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.style.use('seaborn-pastel')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy\n",
    "\n",
    "from scipy import stats # для метода обнаружения Q и IQR,  а также z-корреляции\n",
    "from scipy.stats import mstats\n",
    "\n",
    "np.random.seed(45) # чтобы выборки данных всегда были одни и теже берем любую цифру . мне нравится 45!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8a4c1-73ed-4959-9987-4b44485c0e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Этап 3.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c5f95-ecc9-4324-a211-8b86e7ea2f84",
   "metadata": {},
   "source": [
    "# Проверка того, есть ли в структуре данных какие-либо пропущенные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef9e3a-7f99-4b36-8f47-7241593c2892",
   "metadata": {},
   "source": [
    "# Прочитаем наш df - 'data_composite_inspect.csv' из тетради Diploma1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236172cd-b8b1-4068-9479-eeb7a4eb286c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_composite_inspect = pd.read_csv(r'C:\\Users\\grain\\Work_folder\\Diplom_MGTU\\Diploma1_data\\data_composite_inspect.csv')\n",
    "data_composite_inspect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1ae52-7dd2-4d6d-9ddd-92ece618a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6a696-e1aa-440c-94c1-32704ae52a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea037e-0681-4a2e-9465-eb56e1559f83",
   "metadata": {},
   "source": [
    "В нашем файле 1023 строки и 13 признаков-столбцов. Все значения у нас числовые, тип данных float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dcd96-a7bc-42f6-9797-1779b77186dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Проверим отсутствие: пропущенных и нулевых значений, а также дубликатов строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd11f36-257f-4b78-8f34-fa7e5ae387fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод .isnull() выдает логический массив, где пропуски обозначены как True.\n",
    "# Функция .isnull() используется для проверки того, есть ли в структуре данных какие-либо пропущенные значения.\n",
    "# метод .sum() по умолчанию суммирует эти True или единицы по столбцам (axis = 0)\n",
    "# Можно использовать функцию .isnull() вместе с .sum(), чтобы увидеть количество пропущенных значений в каждом столбце.\n",
    "\n",
    "data_composite_inspect.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eac81-60d9-4c0d-a91e-07bfde6bbee8",
   "metadata": {},
   "source": [
    "Пропущенных значений нет!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0716a-7c86-4fdd-b8a5-3eed6124b824",
   "metadata": {},
   "source": [
    "Проверка того, есть ли в структуре данных какие-либо отсутствующих значений (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8c82c-4fe7-4da7-98c7-f17d0a944ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция .isna() в Pandas используется для обнаружения отсутствующих значений (NaN), \n",
    "# значения NaN в структуре данных сопоставляются с True, а значения, отличные от NaN, сопоставляются с False.\n",
    "# Можно использовать функцию isna вместе с sum, чтобы увидеть количество пропущенных значений в каждом столбце.\n",
    "\n",
    "data_composite_inspect.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1f0a8-9b5e-4109-bd96-4ce31271b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще один метод определения пропущенных значений - Тепловая карта пропущенных значений sns.heatmap\n",
    "\n",
    "cols = data_composite_inspect.columns[:13] # первые 13 колонок\n",
    "# определяем цвета \n",
    "# желтый - пропущенные данные, синий - не пропущенные\n",
    "colours = ['#000099', '#ffff00'] \n",
    "sns.heatmap(data_composite_inspect[cols].isnull(), \n",
    "            cmap=sns.color_palette(colours)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de791b-3b55-454d-a372-aeb496d2ea99",
   "metadata": {
    "tags": []
   },
   "source": [
    "Мы определили, что в нашем DataFrame data_composite_inspect нет  пропущенных значений и отсутствующих значений (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31684ca2-18d7-48bb-8040-9bf6ccc09e5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проверим наш DataFrame на наличие дубликатов  строк "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c372b4-b4e0-440b-8333-e9abd7c89903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем ,если они есть количество дублируеых строк\n",
    "count_dupl = len(data_composite_inspect)-len(data_composite_inspect.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681ac44-8aaf-4dd9-ace7-a9ae8dd84ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_dupl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3780d-9abc-4445-9cc9-316d4374772a",
   "metadata": {},
   "source": [
    "В нашем dataFrame НЕТ дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88be08-6c1f-4cc8-8182-a4aa9a5b25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчет уникальных значеий по каждому признаку\n",
    "df1.apply(lambda x: x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd727d2-eb21-461c-97d6-e906a185e9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем наличие дубликатов в данных\n",
    "df1.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b207cd2b-a1af-4d5a-a766-1a789db72fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!!!!!!!\n",
    "df1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587809b-3d0b-446b-9033-cc0678894130",
   "metadata": {},
   "source": [
    "# Продолжаем исследование нашего df - data_composite_inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667f661-a5e1-4579-bcd7-80fc504c2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод .describe() к количественным признакам\n",
    "# округлим значения до 2-х знаков после запятой - round(3)\n",
    "data_composite_inspect.describe(percentiles = [0.25, 0.5, 0.75], include='all').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf55f94-5acb-4680-9cae-d5ba202d29f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Полный анализ нашего df  можно осуществить с помощью модуля df.profile_report()\n",
    "data_composite_inspect.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27432f-3174-41ce-9e10-11ef35bed1af",
   "metadata": {},
   "source": [
    "# Как выяснилось ,в нашем df есть один категориальный параметр - Угол нашивки- pattern_angle\n",
    "# Переведем этот параметр в числовой \n",
    "Используем модуль OneHotEncoding \n",
    "Использовать LabelEncoder  !!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1d70d-53e6-4a2a-ac90-b1397f2adb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание экземпляра one-hot-encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046a088-4619-483f-8df4-22ee9a5953ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполните однократное кодирование в столбце \"pattern_angle\" \n",
    "encoder_df = pd.DataFrame(encoder.fit_transform(data_composite_inspect[['pattern_angle']]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e2b87-97a4-40dd-b9e0-e245427b0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac539a2-5a9d-43a4-a88e-6d320d31c960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# объедините столбцы с односторонним кодированием обратно с исходным фреймом данных\n",
    "data_composite_inspect = data_composite_inspect.join (encoder_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04315d8f-d42d-4084-ab14-8609e0dd280d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68e01a-13a9-424c-8f15-1fd1c563fb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем исходный столбец 'pattern_angle' column\n",
    "data_composite_inspect.drop('pattern_angle', axis= 1 , inplace= True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655b27b4-0ad5-4f5c-bbed-348bc2027aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_composite_inspect.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca6484-579b-445f-8291-dcaa21867136",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40839e5-3818-4d64-9621-a78985bb9ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем нове столбцы '0' на 'pattern_0_angle', а '90' на 'pattern_90_angle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c257dc-341e-4e44-9cbb-c8a1346d6dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "data_composite_inspect.columns = ['step_strip', 'density_strip',\n",
    "                    'ratio_filler_matrix', 'density',\n",
    "                    'elasticity_module', 'number_hardeners',\n",
    "                    'content_epoxy_groups','flash_temperature',\n",
    "                    'surface_density', 'elasticity_module_stretching',\n",
    "                    'strapery_strength', 'resin_consumption',\n",
    "                    'pattern_0_angle', 'pattern_90_angle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418867f-dd35-4da1-b824-162b7d8b5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68650c80-9591-43cf-ab92-67e0fede99b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще раз проведем полный анализ нашего df  с помощью модуля df.profile_report()\n",
    "data_composite_inspect.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572f2ff-c969-46c5-b9ee-5cf27dcae774",
   "metadata": {},
   "source": [
    "# Первичный Графический анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb257881-d9ed-475e-948f-6874019da231",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Построение графиков\n",
    "# Взято из https://pyprog.pro/sns/sns_6_visualization_of_dist.html\n",
    "\n",
    "# Функция построения основных графиков по парметрам df:  sns.histplot и sns.boxplot, sns.kdeplot, sns.scatterplot и sns.displot\n",
    "# Параметры, передаваемые в функцию:\n",
    "# df- наш dataframe\n",
    "# plt_type - тип графика ,который выводится (histplot, boxplot, displot, kdeplot, catterplot)\n",
    "# n_col - количество столбцов графиков сколько будем строить в строке\n",
    "# figsize_a - размер по ширине\n",
    "# figsize_b - размер по высоте\n",
    "\n",
    "def drawing_graphs(df, n_col, figsize_a, figsize_b, plt_type): # figsize_a, figsize_b - было 12,2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_col, figsize=(figsize_a, figsize_b)) \n",
    "    i = 0              \n",
    "    n_colum  = df.shape[1]  # количество столбцов в df / если 1, то количество столбцов (13), если 0, то строк 1023 !\n",
    "    name_type_plt = plt_type\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if  name_type_plt == 'histplot':\n",
    "            sns.histplot(df[column],ax=axes[i],\n",
    "                         bins = 30, \n",
    "                         kde = True, # оценка плотности ядра (kernel density estimation или сокращенно kde)\n",
    "                         fill = True\n",
    "                         )    \n",
    "        elif   name_type_plt == 'boxplot':       \n",
    "            sns.boxplot(data=df, ax=axes[i],\n",
    "                        x=column,\n",
    "                        )\n",
    "        elif  name_type_plt == 'kdeplot':\n",
    "             sns.kdeplot(df[column], ax=axes[i], \n",
    "                         bw_adjust= 1\n",
    "                        ) \n",
    "        elif  name_type_plt == 'displot':\n",
    "             sns.displot(data =df, ax=axes[i],\n",
    "                         x = column, \n",
    "                         kind = 'kde',\n",
    "                         fill = True\n",
    "                         )\n",
    "\n",
    "        elif  name_type_plt == 'scatterplot':\n",
    "            sns.scatterplot(df[column], ax=axes[i],\n",
    "                            alpha=1,\n",
    "                            color='b'\n",
    "                            )\n",
    "        i = i + 1\n",
    "        if i > (n_col - 1) or column == df.columns[n_colum - 1]:\n",
    "            plt.show()\n",
    "            fig, axes = plt.subplots(1, n_col, figsize=(figsize_a, figsize_b))\n",
    "            i = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa7b7d-2058-4182-8d2c-24af5cb775f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_composite_inspect, 2, 12, 2, 'histplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59b66a-4580-415d-b29e-0978e14cd76a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_composite_inspect, 3, 10, 4, 'scatterplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14917283-907d-472a-bfb0-03e40936b557",
   "metadata": {},
   "source": [
    "# Внимание !!!! первые 40 строк DF  имеют явно искаженный характер и являются искусственно привнесенными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe856c-2014-4e97-a3c4-412c6849332c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_composite_inspect.head(50), 2, 8, 2, 'scatterplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48a92b2-fbc2-4af8-8062-e236ca6c9b07",
   "metadata": {},
   "source": [
    "# Все три признака, представленные в датасете df_nup по первым 20 значениям можно расценивать как дискретные, что вполне оправдано для представленных категорий, однако в диапазоне от 20 и до 1022 данные в колонках \"Плотность нашивки\" и \"Шаг нашивки\" представлены непрерывными значениями.\n",
    "Возможно, данные в диапазоне (20; 1022) были подвергнуты преобразованию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500dd719-0994-449a-bf47-fed5bd3c4310",
   "metadata": {},
   "source": [
    "# Разделим наш датафрейм на три и произведем обучение моделей на двух датафреймах и сопоставим результаты: Датафрейм № 1 - объединенный по индексам датасет без разделения; Датафрейм № 2 - объединенный по индексам датасет за исключением!!!!!!!  первых 39 строк с дискретными значениями; \n",
    "Датафрейм № 3 - экспериментальный, исключающий все дискретные значения;\n",
    "\n",
    "Рссмотрbv DF 2 хотя он и имеет в виду очень маленькую выборку данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d558ad-5a56-47fb-af77-4db22119dbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df.drop(labels=range(0, 39), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb51f0e-cc15-4a74-92d7-572e3ab5f234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5d6e1-e448-4b94-a77a-c2fda675b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data_composite_inspect['density_strip'], alpha=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d64db6-f323-4b28-af1c-505030ea30d7",
   "metadata": {},
   "source": [
    "Взято из GitHub\n",
    "# Построим гистограммы распределения\n",
    "a = 5 # количество строк\n",
    "b = 5 # количество столцбцов\n",
    "c = 1 # инициализация plot counter\n",
    "plt.figure(figsize = (35,35))\n",
    "plt.suptitle('Гистограммы переменных', fontsize = 30)\n",
    "for col in df.columns:\n",
    "    plt.subplot(a, b, c)\n",
    "    sns.histplot(data = df[col], kde=True, color = \"darkblue\")\n",
    "    plt.ylabel(None)\n",
    "    plt.title(col, size = 20)\n",
    "    c += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b300f-2e5e-4167-8a80-a144024bf990",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Графики зависимости параметров друг от друга с плотностью распределения\n",
    "# Нужно ли?\n",
    "sns.pairplot(data_composite_inspect.head(100), diag_kind='kde') #, hue='pattern_angle') df_elements = df.sample(n=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1f67-658a-4163-a740-91c2fd9a9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем анализ данных в нашем df: data_composite_inspect на предмет 'подозрительных значений' и выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6f91f-9cf1-463d-87a3-b6f5789625a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "При анализе df.discribe  и df.profile_report() выяснилось ,что в столбцах 'Шаг нашивки' и 'Плотность нашивки'\n",
    "min значения равны 0.0 ,что не может быть физически."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5940e-8af4-4729-a6cc-988beee08472",
   "metadata": {
    "tags": []
   },
   "source": [
    "А также значения MIN в столбцах:'ratio_filler_matrix'  = 0.389 'этот параметр  не может быть меньше 1,\n",
    "'elasticity_module'= 2.437 это значение на 2 порядка меньше среднего- явная ошибка заполнения,\n",
    "surface_density = 0.604 то значение на 3 порядка меньше среднего- явная ошибка заполнения.\n",
    "\n",
    "Эти МИН значения несоотвествуют физически\n",
    "м параметрм нашего проекта относительно показателей для композитных материлов.\n",
    "И являютя выбросми 'слева'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758eea5d-8afd-4555-ad05-426e73a16d0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def column_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print('столбец : ', column)\n",
    "        print('Интервал значений', '  ', 'Количество в интервале')\n",
    "        print(df[column].value_counts(bins=50))\n",
    "        print('-----------------------------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2f6b5-daf8-44e3-8c7d-cfa4068f06c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_value_counts(data_composite_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f21ea-afc5-4562-be72-0a239c44b5aa",
   "metadata": {},
   "source": [
    "# Мы можем определить интервалы значений, которые можно отбросить  в первом приближении по МИН значению,\n",
    "как противоречищий физическому смыслу: \n",
    "1-й интервал (0.527, 66.074]    строк 16\n",
    " 2-й интервал :\n",
    "'''\n",
    "1529.716, 1593.353]     5\n",
    "(1593.353, 1656.989]     3\n",
    "(1784.263, 1847.899]     1\n",
    "(1847.899, 1911.536]     1\n",
    "(1656.989, 1720.626]     0\n",
    "(1720.626, 1784.263]     0\n",
    "'''\n",
    "и так получим значения крайних -левых значений для DataFrame для каждого столбца в df_min_max!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48a7f5-a4c3-43f3-bdae-0fce8313bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим DataFrame  df_min_max который содержит мин и мах значения по каждому столбу в качестве критерия отбрасывания строк \n",
    "# min - индекс сроки 0 и max- индекс строки 1 получены оценочным путем при исследовании гистограмм по каждому параметру-столбцу\n",
    "# Для столбца 'pattern_angle'диапазон будет :[0.0, 90.0],\n",
    "\n",
    "df_min_max = pd.DataFrame({\n",
    "                     \n",
    "                      'step_strip':[1.5, 13.5],\n",
    "                  'density_strip' :[29.0, 85.6],\n",
    "             'ratio_filler_matrix':[0.5, 6.0],\n",
    "                        'density' :[1780.0, 2159.0],\n",
    "              'elasticity_module' :[50.0, 1560.0],\n",
    "                'number_hardeners':[30.0, 190.0],     \n",
    "            'content_epoxy_groups':[16.0, 28.0],\n",
    "               'flash_temperature':[180.0, 390.0],\n",
    "                'surface_density' :[20.0, 1200.0],\n",
    "    'elasticity_module_stretching':[66.0, 81.0],\n",
    "              'strapery_strength' :[1326.0, 3600.0],\n",
    "               'resin_consumption':[80.0, 350.0],\n",
    "                 'pattern_0_angle':[0.0, 0.0],\n",
    "                'pattern_90_angle':[1.0, 1.0]\n",
    "                          })\n",
    "\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a559a4-9985-44c7-95e8-5dea6cf10b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчета СРЕДНЕГО значения для \"подозрительного элемента\" в столбце с разбросом \n",
    "# как ВЫШЕ так и НИЖЕ от \"подозрительного элемента\"\n",
    "# Передаваемые в функцию параметры:\n",
    "# df[column] - столбец значений в котором сейчас идет проверка\n",
    "# n_row -      номер строки \"подозрительного элемента\"\n",
    "# n_spread -   задаваемый разброс обычно я задаю 5.\n",
    "\n",
    "def mean_round_point(df, column, n_row, n_spread):\n",
    "    mean_n_spread = 0 # возвращаемое значение среднего, полученного из суммы ближайших (n_spread * 2) значений столбца\n",
    "    \n",
    "    higth_value_sum = 0 # Сумма значений, где текущее значение номера строки Меньше (n_spread) \n",
    "    low_value_sum = 0   # Сумма значений,  где текущее значение номера строки Больше (n_spread)\n",
    "    \n",
    "# Для значений столбца, где текущее значение номера строки Меньше (n_spread) - заданного интервала для определения СРЕДНЕГО значения\n",
    "    for n in range(n_spread):\n",
    "        if (n_row == 0) or (n_row - n < 0):\n",
    "            break\n",
    "        else:\n",
    "            higth_value_sum = higth_value_sum + df.loc[n_row - n][column]\n",
    "            n = n + 1    \n",
    "# Для значений столбца, где текущее значение номера строки Больше (n_spread) - заданного интервала для определения СРЕДНЕГО значения\n",
    "    for k in range(n_spread):   \n",
    "        if n_row + k >= len(df[column]):  \n",
    "            break\n",
    "        else:\n",
    "            low_value_sum = low_value_sum + df.loc[n_row + k][column]    \n",
    "            k = k + 1\n",
    "# Рассчитываем суммы n_spread элементов выше (left_value_sum)  и ниже (rigth_value_sum) 'подозрительного элемента' строки n_row\n",
    "    mean_n_spread =  (higth_value_sum + low_value_sum) / (n + k)\n",
    "    print('новое значение :', mean_n_spread)\n",
    "    return mean_n_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cf5a0-671a-4259-9781-7f5128e98009",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_df_left(df, df_min_max):\n",
    "    sum_n_quantity = 0 # Общее количество подозрительных строк в df\n",
    "\n",
    "    for column in df.columns:\n",
    "        if column == 'pattern_0_angle' or column == 'pattern_90_angle':\n",
    "            break\n",
    "        n_col = column\n",
    "        print('подозрительный столбец : ', n_col)\n",
    "        print('экспертное минимально-допустимое значение :', df_min_max.loc[0, n_col])\n",
    "    \n",
    "        n_quantity = 0 # Количество подозрительных строк в столбце\n",
    "       \n",
    "        for i in range(len(df)):\n",
    "            if df.loc[i, n_col] < df_min_max.loc[0, n_col]:\n",
    "                n_quantity =  n_quantity + 1\n",
    "                print('строка N:', i)\n",
    "                print('старое значение :', df.loc[i, n_col])      \n",
    "            # Функция 'mean_round_point' расчета СРЕДНЕГО значения для \"подозрительного элемента\" в столбце с разбросом '5'\n",
    "                df.at[i, n_col] = mean_round_point(df, n_col, i, 5) \n",
    "        print('Количество подозрительных строк в столбце = ', n_quantity)\n",
    "        print('---------------------------------')\n",
    "        sum_n_quantity = sum_n_quantity + n_quantity\n",
    "    print('Общее количество подозрительных строк в df = ', sum_n_quantity)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa86ef-9569-4321-a04e-279103e0e141",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_df_left(data_composite_inspect, df_min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18863c-85d2-4220-9351-a18dea36eb52",
   "metadata": {},
   "source": [
    "всего замена подозрительных значений слева произведена в 106 строках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d23152-694e-4aa8-adb0-8e3f1df5d361",
   "metadata": {},
   "source": [
    "Проведем очистку нашег df (в котором 1023 строки) от выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb80768-6546-4da1-925e-0f72855137ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Способ удаления выбросов IQR.\n",
    "Записшем очищеный массив в df - data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01194043-2c38-4d5b-99bf-1f8c432c5d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.codecamp.ru/blog/remove-outliers-python/\n",
    "# find Q1, Q3, and interquartile range for each column\n",
    "# создаем новый df: data_clean\n",
    "\n",
    "def outliers_delit(df):\n",
    "    Q1 = df.quantile(q=.25)\n",
    "    Q3 = df.quantile(q=.75) \n",
    "    IQR = df.apply(stats.iqr) # from scipy import stats\n",
    "\n",
    "#only keep rows in dataframe that have values within 1.5\\*IQR of Q1 and Q3\n",
    "\n",
    "    data_clean = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "#find how many rows are left in the dataframe \n",
    "\n",
    "    data_clean.shape\n",
    "    print('Количество строк до удаления: ', len(df))\n",
    "    print('Количество строк после удаления: ', len(data_clean))\n",
    "    print('Удалено строк :', (len(df) - len(data_clean)))\n",
    "    \n",
    "    return(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11037c55-c87f-45bf-8285-b7144b6e3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = outliers_delit(data_composite_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4688e8d-f55e-4bbd-8630-1413efbb2360",
   "metadata": {},
   "source": [
    "#### У нас было 1023 строки  до применения метода IQR. Теперь мы получили после очистки 936 строк в df -  data_clean.\n",
    "Удлили 61 строк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea788a-1dff-4919-b7d7-51c47d95e57f",
   "metadata": {},
   "source": [
    "второй способ z-с  посмотрим сколько строк уберет этот метод из  массива data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bc9a6-3dd5-4a59-a60e-63e7435a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the function to calculate the Z - Score\n",
    "def Z_score(data):\n",
    "    global outliers,zscore\n",
    "    outliers = []\n",
    "    zscore = []\n",
    "    upper_threshold = 3\n",
    "    lower_threshold = -3\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    for i in data:\n",
    "        z_score= (i - mean)/std \n",
    "        zscore.append(z_score)\n",
    "        if np.abs(z_score) > upper_threshold or np.abs(z_score) < lower_threshold:\n",
    "            outliers.append(i)\n",
    "    return print(\"Total number of outliers are\",len(outliers)) #outliers,,  zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4059d-c4f4-4d8c-9338-c061271f89a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function calling\n",
    "for column in data_clean.columns:\n",
    "    Z_score(data_clean[column])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c3e41-c6be-4a79-a046-13b169457f02",
   "metadata": {},
   "source": [
    "Данный метод Z - Score НЕ нашел возможных для удаления строк!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6808b-4e33-44cf-87de-18f94b9e555d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проведем  графический анализ имеющихся  выбросов данных в data_clean методом sns.boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867a8fc-dad0-4bd7-b703-00b917b782f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_clean, 2, 12, 2, 'boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a51dd-b4ae-41de-8473-63743a2dd2b2",
   "metadata": {},
   "source": [
    "У нас в 2-х столбцах наблюаются выбросы после замены 'подозрительных значений' СПРАВА на средние значения +/- 5 значений в столбце и очистки стандартными методами IQR и Z-C.\n",
    "Проведем дополнительную очистку  в столбцах: 'elasticity_module_stretching' и 'strapery_strength'.\n",
    "Используем функцию \"Методом подбора коэффициентов в df_min_max\" и удалением этих выбросов в df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562882a-c333-4dd0-98db-b06510162f9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проведем иттерацию по удалению строк из нашего df со значениями в df_min_max  при max- строка '1'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370575b-4b13-4109-a4af-f51e3bd26ca4",
   "metadata": {},
   "source": [
    "Проведем очистку каждого парметра от значений  'max' лежащих дальше чем 3 СИГМА  'elasticity_module_stretching' и 'strapery_strength'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2c618-6861-4e17-8c9b-82d96843ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция очистки значений в стлбцах СПРАВА\n",
    "# пердаваемые параметры:\n",
    "# df - наш массив\n",
    "# df_min_max - массив экпертных крайних сначений для каждого столбца\n",
    "# df_name_column - массив наименований столбцов ,в которых необходимо провести очистку СПРАВА\n",
    "\n",
    "def clean_column_rigth(df, df_min_max, df_name_column):\n",
    "    sum_del_rigth = 0 # Количество строк удаленных выбросов СПРАВА после определения столбцов с выбросами в boxplot\n",
    "    # df_name_column = pd.DataFrame(columns=list_name_column)\n",
    "    for name_col in df_name_column.columns:\n",
    "        for column in df.columns:\n",
    "            if column != name_col:\n",
    "                continue\n",
    "            l_begin = len(df)\n",
    "            df = df[(df[column] < df_min_max.loc[1, column])]     \n",
    "            l_end = len(df)\n",
    "            list_x = l_begin - l_end\n",
    "            print(df.shape)\n",
    "            print('Количество подозрительных строк в столбце = ', list_x)\n",
    "            print('---------------------------------')\n",
    "        sum_del_rigth = sum_del_rigth + list_x\n",
    "    print('Общее количество удалнных подозрительных строк из-за выбросов справа в df = ', sum_del_rigth)\n",
    "    #data_clean = data_clean_def  \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6c8dc-8c60-4fd6-a9a9-aadc6603183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список столбцов и df, где есть выбросы СПРАВА для передачи в  функцию clean_column_rigth\n",
    "list_name_column = ['elasticity_module_stretching', 'strapery_strength']\n",
    "df_name_column = pd.DataFrame(columns=list_name_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07607ee4-4e7f-4674-a18a-f5f4d64963bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = clean_column_rigth(data_clean, df_min_max, df_name_column)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46af12-dec7-4d83-bed2-9848c7e21405",
   "metadata": {},
   "source": [
    "Удалили 11 строк с выбросами справа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187c30d-5296-4b98-a999-f546f89eb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество строк до очистки df: ', len(data_composite_inspect))\n",
    "print('Количество строк после очистки: ', len(data_clean))\n",
    "print('Удалено строк :', (len(data_composite_inspect) - len(data_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bc0ee-c91f-47fc-89fd-238394a99fd8",
   "metadata": {},
   "source": [
    "В начальном DF  у нас было 1023 строки, сейчас осталось 951 строк. Всего удалили  72 строк на данной иттерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ed2f7-90e4-4cc8-83af-4fa0fa23fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опять проверим на выбросы наш df  на примере графиков 'ящиков с усами' для каждого столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7288de-91bc-4039-ab5c-267c2122997d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_clean, 2, 12, 2, 'boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a562f24-8c8c-4b5b-af8e-71255fb9f9f9",
   "metadata": {},
   "source": [
    "В нашем df опять появились выбросы после удаления 11 из-за выбросов СПРАВА по функции clean_column_rigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62907ad8-aa7b-46e0-bd42-26e97b53d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 'df_min_max' который содержит мин и мах значения по каждому столбу в качестве критерия отбрасывания строк \n",
    "# min - индекс сроки 0 и max- индекс строки 1 получены оценочным путем при исследовании гистограмм по каждому параметру-столбцу\n",
    "# Изменим значение в df_min_max в столбце  'elasticity_module' :[50.0, 1560.0] на значения 'elasticity_module' :[50.0, 1550.0]\n",
    "\n",
    "df_min_max =  df_min_max.replace({'elasticity_module' : { 50.0 : 50.0, 1560.0 : 1550.0}})\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce4d49-1bb2-4b23-85a5-e26939ab4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следующая иттерация по удалению выбросов СПРАВА \n",
    "# Список столбцов, где есть выбросы СПРАВА для передачи в  функцию clean_column_rigth\n",
    "list_name_column = ['elasticity_module']\n",
    "df_name_column = pd.DataFrame(columns=list_name_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee2717-9054-4278-adb5-9608794af0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторно вызываем функцию clean_column_rigth\n",
    "data_clean = clean_column_rigth(data_clean, df_min_max, df_name_column)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34363550-57df-4ed2-8c74-b62dcf2c8f39",
   "metadata": {},
   "source": [
    "В столбце 'elasticity_module' удалили еще 3 строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597272d-8988-41c4-9aca-e326d5f58131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем еще одну иттерацию проврки df с  помощью boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ac4ea-2287-41b7-9f45-68a807bd8aa7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_clean, 2, 12, 2, 'boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1b20b-9f14-47f3-8990-b41303334693",
   "metadata": {},
   "source": [
    "# У нас получились \"чистые \", без выброов \"ящики с усами\"!\n",
    "Перейдем к следующему этапу исследования нашего datafrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a42113-bbe2-4756-88ae-f58a70c6d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество строк до очистки df: ', len(data_composite_inspect))\n",
    "print('Количество строк после очистки: ', len(data_clean))\n",
    "print('Удалено строк :', (len(data_composite_inspect) - len(data_clean)))\n",
    "total_del_percent = ((len(data_composite_inspect) - len(data_clean)) / len(data_composite_inspect)) * 100\n",
    "print('Удалено : ', total_del_percent, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610a741-b8b3-43d4-b6fe-fac53d2d1b9b",
   "metadata": {},
   "source": [
    "В начальном DF  у нас было 1023 строки, сейчас осталось 948 строк. Всего удалили  75 строк или 7.33 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4324312-ebce-4287-8092-3f05474674b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Запишим data_clean в новый файл 'data_main.csv' для дальнейшей работы и передачи в pipline и изучением методами sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85edc49-d271-4f1d-b2bc-72f92eb1aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишим data_clean в новый файл 'data_main.csv' для дальнейшей работы и передачи в pipline и изучением методами sklearn\n",
    "# В массиве 'data_main.csv' мы:\n",
    "# 1. Заменили нулевые значения '0.0' в строке 19 столбцов 'Шаг нашивки' - 'step_strip'\n",
    "# и 'Плотность нашивки' - 'density_strip'\n",
    "# 2.Удалили параметр 'Угол нашивки' - 'pattern_angle' как не несущий существенной информации , так как там всего 2 значения угла  и 90 град распределенных по 50% \n",
    "# 3. Провели очистку выбросов методом IQR  и удалили еще 76 строк.\n",
    "# 4. Метод  Z - Score не нашел дополнительные выбросы\n",
    "# 5. Проведя графический аналих по boxpot,  мы убедились что в ряде столбцов остались выбросы. Чтобы убрать оставшиеся выбросы,\n",
    "#  мы в ручном режиме в цикле убрали по шаблону df_min_max значния меньше МИН и больше МАХ . Всего еще 21 строку.\n",
    "# Всего мы удалили 1023 - 941 = 82 строк  или 8 % из исходного файла \n",
    "# Считаем, что df очищен от выбросов\n",
    "\n",
    "data_clean.to_csv('data_main.csv', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a709e42-5687-4ffa-be3d-e3391f6b7516",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#  Этап 4 Нормализуем и стандартизируем наш dataset, чтобы привести наши данные к близким размерностям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ce385-636c-4c52-83ce-d2820b17a05d",
   "metadata": {},
   "source": [
    "# В нашем DataSet \"data_composite_inspect\" есть 12 признаков- столбцов\n",
    "Но все признаки имеют разную размерность.\n",
    "Нормализуем и стандартизируем  наш массив \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b704692-cffb-4051-92a0-3371c59f67fd",
   "metadata": {},
   "source": [
    "# Этап 4.1 Нормализация по методу MinMaxskaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0767b77-e28f-4303-9fe7-ef2fd895e0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# список наших столбцов\n",
    "list_data = list(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30134a-1408-41df-bf0c-6d17fd5a436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler() # вызываем метод MinMaxskaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cae99-44d7-47e1-a2fa-a8d48389ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  обучаем MinMaxScaler() -передаем только числовые значения столбцов  ,указанных списком list_data или можно перечислить какие нужны\n",
    "data_clean_norm = minmax_scaler.fit_transform(np.array(data_clean[list_data])) \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be985c0-8672-4574-ae89-91f1630ae44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_norm[:1] # Проверим первую строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c73e3-ff17-4b60-87ba-aa4c3f77d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый df с нормализованными данными с названием наших столбцов \n",
    "data_clean_norm_df = pd.DataFrame(data = data_clean_norm, columns = list_data)\n",
    "data_clean_norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cd34c-d2b9-4dbe-a831-7c6f085d1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_norm_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff503da-5a93-4fcc-836d-d59b5415347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем нормализованный очищеный от выбросов df\n",
    "data_clean_norm_df.to_csv('data_main_norm.csv', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e49338-d7f4-4cd5-b451-dce8d8259921",
   "metadata": {},
   "source": [
    "# 4.2 Проведем стандартизацию по методу StandardSckaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88208abd-c6b9-4bbf-ae48-7bd9dd84302b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2ceb4-833f-4b6a-8d8a-bf43a299e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# список наших столбцов\n",
    "list_data = list(data_clean)\n",
    "\n",
    "std_skaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df44d8-f97e-4b05-8047-f7a1b7aaf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  обучаем StandartSkaler() - передаем только числовые значения столбцов  ,указанных списком list_data или можно перечислить какие нужны\n",
    "data_clean_std = std_skaler.fit_transform(np.array(data_clean[list_data])) \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbe99d-73fc-4c11-b23e-5a5c808fd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_std[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b7cbd-cff0-4283-82d0-e9d279cd7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый df со стандартизованными данными с названием наших столбцов  (вернем их)\n",
    "data_clean_std_df = pd.DataFrame(data = data_clean_std, columns = list_data)\n",
    "data_clean_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad857c-a1fd-4123-bb5c-cb9cc939b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_std_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d6101-4603-4199-bcba-aa191011a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишем стандартизованный очищеный от выбросов df\n",
    "data_clean_std_df.to_csv('data_main_std.csv', index=False, float_format=\"%.3f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

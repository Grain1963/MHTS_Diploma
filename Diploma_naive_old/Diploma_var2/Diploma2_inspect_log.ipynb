{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a88dddc8-1b72-4fc1-8132-801809339895",
   "metadata": {},
   "source": [
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html\n",
    "\n",
    "При решении задач регрессии используются именно регрессоры. Из хороших классических алгоритмов - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07e255-99e8-450a-bfd3-94d142208a5c",
   "metadata": {},
   "source": [
    "В этой тетради мы будем исследовать наш df  на предмет пропусков, нулевых значений выбросов и занчений ,которые противоречат физике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78edf10-c1a5-4d7b-9791-8dbecc50e736",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Импортируем в проект требуемые библиотеки\n",
    "\n",
    "import pandas as pd # библиотека для обработки и анализа данных\n",
    "import numpy as np\n",
    "import seaborn as sns # библиотека для создания статистических графиков\n",
    "import random #  генераторатор случайных чисел и данных\n",
    "import os # библиотека функций для работы с операционной системой.\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "\n",
    "import ydata_profiling # pandas_profiling!!!! отменяется c 1-го апреля 2023 г\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "matplotlib.style.use('seaborn-pastel')\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy\n",
    "\n",
    "from scipy import stats # для метода обнаружения Q и IQR,  а также z-корреляции\n",
    "from scipy.stats import mstats\n",
    "\n",
    "np.random.seed(45) # чтобы выборки данных всегда были одни и теже берем любую цифру . мне нравится 45!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8a4c1-73ed-4959-9987-4b44485c0e93",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Этап 3.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c5f95-ecc9-4324-a211-8b86e7ea2f84",
   "metadata": {},
   "source": [
    "# Проверка того, есть ли в структуре данных какие-либо пропущенные значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ef9e3a-7f99-4b36-8f47-7241593c2892",
   "metadata": {},
   "source": [
    "# Прочитаем наш df - 'data_composite_inspect.csv' из тетради Diploma1_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236172cd-b8b1-4068-9479-eeb7a4eb286c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_composite_inspect = pd.read_csv(r'C:\\Users\\grain\\Work_folder\\Diplom_MGTU\\Diploma1_data\\data_composite_inspect.csv')\n",
    "data_composite_inspect.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f1ae52-7dd2-4d6d-9ddd-92ece618a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a6a696-e1aa-440c-94c1-32704ae52a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea037e-0681-4a2e-9465-eb56e1559f83",
   "metadata": {},
   "source": [
    "В нашем файле 1023 строки и 13 признаков-столбцов. Все значения у нас числовые, тип данных float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0dcd96-a7bc-42f6-9797-1779b77186dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Проверим отсутствие: пропущенных и нулевых значений, а также дубликатов строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd11f36-257f-4b78-8f34-fa7e5ae387fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# метод .isnull() выдает логический массив, где пропуски обозначены как True.\n",
    "# Функция .isnull() используется для проверки того, есть ли в структуре данных какие-либо пропущенные значения.\n",
    "# метод .sum() по умолчанию суммирует эти True или единицы по столбцам (axis = 0)\n",
    "# Можно использовать функцию .isnull() вместе с .sum(), чтобы увидеть количество пропущенных значений в каждом столбце.\n",
    "\n",
    "data_composite_inspect.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9eac81-60d9-4c0d-a91e-07bfde6bbee8",
   "metadata": {},
   "source": [
    "Пропущенных значений нет!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0716a-7c86-4fdd-b8a5-3eed6124b824",
   "metadata": {},
   "source": [
    "Проверка того, есть ли в структуре данных какие-либо отсутствующих значений (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8c82c-4fe7-4da7-98c7-f17d0a944ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Функция .isna() в Pandas используется для обнаружения отсутствующих значений (NaN), \n",
    "# значения NaN в структуре данных сопоставляются с True, а значения, отличные от NaN, сопоставляются с False.\n",
    "# Можно использовать функцию isna вместе с sum, чтобы увидеть количество пропущенных значений в каждом столбце.\n",
    "\n",
    "data_composite_inspect.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1f0a8-9b5e-4109-bd96-4ce31271b86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще один метод определения пропущенных значений - Тепловая карта пропущенных значений sns.heatmap\n",
    "\n",
    "cols = data_composite_inspect.columns[:13] # первые 13 колонок\n",
    "# определяем цвета \n",
    "# желтый - пропущенные данные, синий - не пропущенные\n",
    "colours = ['#000099', '#ffff00'] \n",
    "sns.heatmap(data_composite_inspect[cols].isnull(), \n",
    "            cmap=sns.color_palette(colours)\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de791b-3b55-454d-a372-aeb496d2ea99",
   "metadata": {
    "tags": []
   },
   "source": [
    "Мы определили, что в нашем DataFrame data_composite_inspect нет  пропущенных значений и отсутствующих значений (NaN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31684ca2-18d7-48bb-8040-9bf6ccc09e5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проверим наш DataFrame на наличие дубликатов  строк "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c372b4-b4e0-440b-8333-e9abd7c89903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдем ,если они есть количество дублируеых строк\n",
    "count_dupl = len(data_composite_inspect)-len(data_composite_inspect.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681ac44-8aaf-4dd9-ace7-a9ae8dd84ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_dupl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb3780d-9abc-4445-9cc9-316d4374772a",
   "metadata": {},
   "source": [
    "В нашем dataFrame НЕТ дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587809b-3d0b-446b-9033-cc0678894130",
   "metadata": {},
   "source": [
    "# Продолжаем исследование нашего df - data_composite_inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1667f661-a5e1-4579-bcd7-80fc504c2ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод .describe() к количественным признакам\n",
    "# округлим значения до 2-х знаков после запятой - round(3)\n",
    "data_composite_inspect.describe(percentiles = [0.25, 0.5, 0.75], include='all').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf55f94-5acb-4680-9cae-d5ba202d29f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Полный анализ нашего df  можно осуществить с помощью модуля df.profile_report()\n",
    "data_composite_inspect.profile_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0572f2ff-c969-46c5-b9ee-5cf27dcae774",
   "metadata": {},
   "source": [
    "#Графический анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c15ed-e9b2-430e-af2a-9c47875c69f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Взято из https://pyprog.pro/sns/sns_6_visualization_of_dist.html\n",
    "# Создаем экземпляр класса:\n",
    "g = sns.PairGrid(data_composite_inspect) #.head(100)) # head(100) можно ли вставить  этот параметр???\n",
    "\n",
    "# задаем тип графиков над\n",
    "# главной диагональю:\n",
    "g.map_upper(sns.scatterplot, alpha=0.5) #, hue = 'pattern_angle')\n",
    "\n",
    "# задаем тип графиков под\n",
    "# главной диагональю:\n",
    "g.map_lower(sns.kdeplot, bw_adjust=0.7) #, hue = 'pattern_angle')\n",
    "\n",
    "# задаем тип графиков на\n",
    "# главной диагонали:\n",
    "g.map_diag(sns.histplot, kde=True, bins = 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb257881-d9ed-475e-948f-6874019da231",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Построение графиков\n",
    "# Взято из https://pyprog.pro/sns/sns_6_visualization_of_dist.html\n",
    "\n",
    "# Функция построения графиков по парметрам df:  sns.histplot и sns.boxplot\n",
    "# Параметры, передаваемые в функцию:\n",
    "# df- наш dataframe\n",
    "# plt_type - тип графика ,который выводится (hist - histplot, box - boxplot, dis - displot. kde - kdeplot)\n",
    "# n_row - количестворядов графиков\n",
    "# n_col - количество столбцов графиков\n",
    "\n",
    "def drawing_graphs(df, plt_type, n_row, n_col):\n",
    "    \n",
    "    fig, axes = plt.subplots(n_row, n_col) # в нашем примере : 2, 2\n",
    "    i = 0              # количество графиков во фрейме\n",
    "    n_colum  = df.shape[1]  # количество столбцов в df / если 1, то количество столбцов (13), если 0, то строк 1023 !\n",
    "    \n",
    "    for column in df.columns:\n",
    "        if plt_type = hist:\n",
    "            sns.histplot(df[column],ax=axes[0, i],\n",
    "                         bins = 30, \n",
    "                         kde = True, # оценкf плотности ядра (kernel density estimation или сокращенно kde)\n",
    "                         fill = True\n",
    "                         )    \n",
    "        elif  plt_type = box:       \n",
    "            sns.boxplot(data=df, x=column, ax=axes[1, i])\n",
    "        elif plt_type = kde:\n",
    "             sns.kdeplot(df[column], ax=axes[0, i], \n",
    "                         bins = 30,\n",
    "                         bw_adjust=0.7\n",
    "                        ) \n",
    "        elif plt_type = dis:\n",
    "             sns.displot(data =df, x = column, \n",
    "                         kind = 'kde',\n",
    "                         fill = True\n",
    "                        )\n",
    "        elif plt_type = scatter\n",
    "            sns.scatterplot(df[column], ax=axes[0, i],\n",
    "                            alpha=0.5\n",
    "                           )\n",
    "        i = i + 1\n",
    "        if i > (n_col - 1) or column == df.columns[n_colum - 1]:\n",
    "            plt.show()\n",
    "            fig, axes = plt.subplots(n_row, n_col)\n",
    "            i = 0\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa7b7d-2058-4182-8d2c-24af5cb775f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs(data_composite_inspect, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca21cc-bc4f-4442-8097-1221a35b9a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "Нужно ли?\n",
    "i = 1\n",
    "for column1 in df.columns:\n",
    "    for column2 in df.columns[i:]:\n",
    "        sns.jointplot(data=df, x=df[column1], y=df[column2], hue=\"Угол нашивки, град\")\n",
    "        plt.show()\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe856c-2014-4e97-a3c4-412c6849332c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6f49f-e4cb-4f13-ba6f-199bafa637ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# История с  логорифмом __________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d9cd3b-56a9-49f5-91a3-9dd8ade18db7",
   "metadata": {},
   "source": [
    "Взято https://habr.com/ru/post/557998/\n",
    "Данные гистограммы параметра 'surface_density' показывают четко выраженную асимметрию. \n",
    "Хвост с правой стороны намного длиннее, чем с левой, и поэтому мы говорим, что асимметрия - положительная. \n",
    "Мы можем оценить асимметрию данных количественно при помощи функции библиотеки pandas skew:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3210cb08-fd9e-4439-87ec-763ae28d440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect['surface_density'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87aed3-cc22-424a-90f1-2db806f61e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эта асимметрия может быть эффективным образом смягчена \n",
    "# путем взятия логарифма веса при помощи функции библиотеки numpy np.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625baaba-4ed6-4aa9-ba42-5796903b01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# А теперь уберем ассиметрию в 'surface_density'с помощью (np.log) предварительно создав новый df: df_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73ddd2-9e71-4cd1-8f6b-b9d30ca0d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log = data_composite_inspect.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c45b98-cf3d-4a61-b066-def7d3a3544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log['surface_density'] = np.log(df_log['surface_density'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b4dab-bbd4-4dde-9d3a-4ee33a04e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем первоначальную гистаграмму 'surface_density' в df: data_composite_inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d60d8a3-1f5b-408f-bb72-f938ddd61e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_composite_inspect['surface_density'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ca4b6-ce28-41ab-a85c-66d7c598186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# а теперь гистограмму 'surface_density' из df: df_log\n",
    "df_log['surface_density'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f044d4-cd81-4d59-bcb0-4608e1b3acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_log['surface_density'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5c94a-dea0-48fd-a8ad-377d8c3655cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# гистограмма 'surface_density' сместилась вправо и стала отризательной ,но мы ушли от значений 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0570584-195b-411c-957c-e6654a707034",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Визуализация корреляции '''\n",
    " \n",
    "xs = data_composite_inspect['strapery_strength']\n",
    "ys = data_composite_inspect['surface_density'].apply( np.log )\n",
    "pd.DataFrame(np.array([xs,ys]).T).plot.scatter(0, 1, s=12, grid=True)\n",
    "plt.xlabel('strapery_strength')\n",
    "plt.ylabel('Логарифмическая surface_density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bf051-db2e-4d69-bec5-6107eecf2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Конец истории с логарифмом__________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b300f-2e5e-4167-8a80-a144024bf990",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Графики зависимости параметров друг от друга с плотностью распределения\n",
    "# Нужно ли?\n",
    "sns.pairplot(data_composite_inspect.head(100), diag_kind='kde') #, hue='pattern_angle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d1f67-658a-4163-a740-91c2fd9a9847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем анализ данных в нашем df: data_composite_inspect на предмет 'подозрительных значений' и выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e6f91f-9cf1-463d-87a3-b6f5789625a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "При анализе df.discribe  и df.profile_report() выяснилось ,что в столбцах 'Шаг нашивки' и 'Плотность нашивки'\n",
    "min значения равны 0.0 ,что не может быть физически."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5940e-8af4-4729-a6cc-988beee08472",
   "metadata": {
    "tags": []
   },
   "source": [
    "А также значения MIN в столбцах:'ratio_filler_matrix'  = 0.389 'этот параметр  не может быть меньше 1,\n",
    "'elasticity_module'= 2.437 это значение на 2 порядка меньше среднего- явная ошибка заполнения,\n",
    "surface_density = 0.604 то значение на 3 порядка меньше среднего- явная ошибка заполнения.\n",
    "\n",
    "Эти МИН значения несоотвествуют физически\n",
    "м параметрм нашего проекта относительно показателей для композитных материлов.\n",
    "И являютя выбросми 'слева'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758eea5d-8afd-4555-ad05-426e73a16d0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def column_value_counts(df):\n",
    "    for column in df.columns:\n",
    "        print('столбец : ', column)\n",
    "        print('Интервал значений', '  ', 'Количество в интервале')\n",
    "        print(df[column].value_counts(bins=30))\n",
    "        print('-----------------------------')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2f6b5-daf8-44e3-8c7d-cfa4068f06c9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_value_counts(data_composite_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bfcb72-ce8a-4997-a955-bc408a2424df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мы можем определить интервалы значений, которые можно отбросить  в первом приближении по МИН значению,\n",
    "# как противоречищий физическому смыслу: \n",
    "# 1-й интервал (0.527, 66.074]    строк 16\n",
    "# 2-й интервал :\n",
    "'''\n",
    "1529.716, 1593.353]     5\n",
    "(1593.353, 1656.989]     3\n",
    "(1784.263, 1847.899]     1\n",
    "(1847.899, 1911.536]     1\n",
    "(1656.989, 1720.626]     0\n",
    "(1720.626, 1784.263]     0\n",
    "'''\n",
    "#  и так получим значения крайних -левых значений для DataFrame для каждого столбца в df_min_max!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf48a7f5-a4c3-43f3-bdae-0fce8313bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим DataFrame  df_min_max который содержит мин и мах значения по каждому столбу в качестве критерия отбрасывания строк \n",
    "# min - индекс сроки 0 и max- индекс строки 1 получены оценочным путем при исследовании гистограмм по каждому параметру-столбцу\n",
    "# Для столбца 'pattern_angle'диапазон будет :[0.0, 90.0],\n",
    "\n",
    "df_min_max = pd.DataFrame({\n",
    "                   'pattern_angle':[0.0, 90.0],  \n",
    "                      'step_strip':[1.5, 13.5],\n",
    "                  'density_strip' :[29.0, 85.6],\n",
    "             'ratio_filler_matrix':[0.5, 6.0],\n",
    "                        'density' :[1780.0, 2159.0],\n",
    "              'elasticity_module' :[50.0, 1560.0],\n",
    "                'number_hardeners':[30.0, 190.0],     \n",
    "            'content_epoxy_groups':[16.0, 28.0],\n",
    "               'flash_temperature':[180.0, 390.0],\n",
    "                'surface_density' :[20.0, 1200.0],\n",
    "    'elasticity_module_stretching':[66.0, 81.0],\n",
    "              'strapery_strength' :[1326.0, 3600.0],\n",
    "               'resin_consumption':[80.0, 350.0]          \n",
    "               })\n",
    "\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a559a4-9985-44c7-95e8-5dea6cf10b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчета СРЕДНЕГО значения для \"подозрительного элемента\" в столбце с разбросом \n",
    "# как ВЫШЕ так и НИЖЕ от \"подозрительного элемента\"\n",
    "# Передаваемые в функцию параметры:\n",
    "# df[column] - столбец значений в котором сейчас идет проверка\n",
    "# n_row -      номер строки \"подозрительного элемента\"\n",
    "# n_spread -   задаваемый разброс обычно я задаю 5.\n",
    "\n",
    "def mean_round_point(df, column, n_row, n_spread):\n",
    "    mean_n_spread = 0 # возвращаемое значение среднего, полученного из суммы ближайших (n_spread * 2) значений столбца\n",
    "    \n",
    "    higth_value_sum = 0 # Сумма значений, где текущее значение номера строки Меньше (n_spread) \n",
    "    low_value_sum = 0   # Сумма значений,  где текущее значение номера строки Больше (n_spread)\n",
    "    \n",
    "# Для значений столбца, где текущее значение номера строки Меньше (n_spread) - заданного интервала для определения СРЕДНЕГО значения\n",
    "    for n in range(n_spread):\n",
    "        if (n_row == 0) or (n_row - n < 0):\n",
    "            break\n",
    "        else:\n",
    "            higth_value_sum = higth_value_sum + df.loc[n_row - n][column]\n",
    "            n = n + 1    \n",
    "# Для значений столбца, где текущее значение номера строки Больше (n_spread) - заданного интервала для определения СРЕДНЕГО значения\n",
    "    for k in range(n_spread):   \n",
    "        if n_row + k >= len(df[column]):  \n",
    "            break\n",
    "        else:\n",
    "            low_value_sum = low_value_sum + df.loc[n_row + k][column]    \n",
    "            k = k + 1\n",
    "# Рассчитываем суммы n_spread элементов выше (left_value_sum)  и ниже (rigth_value_sum) 'подозрительного элемента' строки n_row\n",
    "    mean_n_spread =  (higth_value_sum + low_value_sum) / (n + k)\n",
    "    print('новое значение :', mean_n_spread)\n",
    "    return mean_n_spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48cf5a0-671a-4259-9781-7f5128e98009",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_df_left(df, df_min_max):\n",
    "    sum_n_quantity = 0 # Общее количество подозрительных строк в df\n",
    "\n",
    "    for column in df.columns:\n",
    "        n_col = column\n",
    "        print('подозрительный столбец : ', n_col)\n",
    "        print('экспертное минимально-допустимое значение :', df_min_max.loc[0, n_col])\n",
    "    \n",
    "        n_quantity = 0 # Количество подозрительных строк в столбце\n",
    "       \n",
    "        for i in range(len(df)):\n",
    "            if df.loc[i, n_col] < df_min_max.loc[0, n_col]:\n",
    "                n_quantity =  n_quantity + 1\n",
    "                print('строка N:', i)\n",
    "                print('старое значение :', df.loc[i, n_col])      \n",
    "            # Функция 'mean_round_point' расчета СРЕДНЕГО значения для \"подозрительного элемента\" в столбце с разбросом '5'\n",
    "                df.at[i, n_col] = mean_round_point(df, n_col, i, 5) \n",
    "        print('Количество подозрительных строк столбце = ', n_quantity)\n",
    "        print('---------------------------------')\n",
    "        sum_n_quantity = sum_n_quantity + n_quantity\n",
    "    print('Общее количество подозрительных строк в df = ', sum_n_quantity)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa86ef-9569-4321-a04e-279103e0e141",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_df_left(data_composite_inspect, df_min_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf18863c-85d2-4220-9351-a18dea36eb52",
   "metadata": {},
   "source": [
    "всего замена подозрительных значений слева произведена в 106 строках"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d23152-694e-4aa8-adb0-8e3f1df5d361",
   "metadata": {},
   "source": [
    "Проведем очистку нашег df (в котором 1023 строки) от выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb80768-6546-4da1-925e-0f72855137ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Способ удаления выбросов IQR.\n",
    "Записшем очищеный массив в df - data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01194043-2c38-4d5b-99bf-1f8c432c5d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.codecamp.ru/blog/remove-outliers-python/\n",
    "# find Q1, Q3, and interquartile range for each column\n",
    "# создаем новый df: data_clean\n",
    "\n",
    "def outliers_delit(df):\n",
    "    Q1 = df.quantile(q=.25)\n",
    "    Q3 = df.quantile(q=.75) \n",
    "    IQR = df.apply(stats.iqr) # from scipy import stats\n",
    "\n",
    "#only keep rows in dataframe that have values within 1.5\\*IQR of Q1 and Q3\n",
    "\n",
    "    data_clean = df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "#find how many rows are left in the dataframe \n",
    "\n",
    "    data_clean.shape\n",
    "    print('Количество строк до удаления: ', len(df))\n",
    "    print('Количество строк после удаления: ', len(data_clean))\n",
    "    print('Удалено строк :', (len(df) - len(data_clean)))\n",
    "    \n",
    "    return(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11037c55-c87f-45bf-8285-b7144b6e3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = outliers_delit(data_composite_inspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4688e8d-f55e-4bbd-8630-1413efbb2360",
   "metadata": {},
   "source": [
    "#### У нас было 1023 строки  до применения метода IQR. Теперь мы получили после очистки 936 строк в df -  data_clean.\n",
    "Удлили 61 строк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea788a-1dff-4919-b7d7-51c47d95e57f",
   "metadata": {},
   "source": [
    "второй способ z-с  посмотрим сколько строк уберет этот метод из  массива data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54bc9a6-3dd5-4a59-a60e-63e7435a9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining the function to calculate the Z - Score\n",
    "def Z_score(data):\n",
    "    global outliers,zscore\n",
    "    outliers = []\n",
    "    zscore = []\n",
    "    upper_threshold = 3\n",
    "    lower_threshold = -3\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    for i in data:\n",
    "        z_score= (i - mean)/std \n",
    "        zscore.append(z_score)\n",
    "        if np.abs(z_score) > upper_threshold or np.abs(z_score) < lower_threshold:\n",
    "            outliers.append(i)\n",
    "    return print(\"Total number of outliers are\",len(outliers)) #outliers,,  zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4059d-c4f4-4d8c-9338-c061271f89a0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Function calling\n",
    "for column in data_clean.columns:\n",
    "    Z_score(data_clean[column])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c3e41-c6be-4a79-a046-13b169457f02",
   "metadata": {},
   "source": [
    "Данный метод Z - Score НЕ нашел возможных для удаления строк!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6808b-4e33-44cf-87de-18f94b9e555d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проведем  графический анализ имеющихся данных в data_clean методом sns.boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05070617-5291-4dac-ac0a-5949b2e1394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция построения графиков по парметрам df:  sns.boxplot\n",
    "# Параметры, передаваемые в функцию:\n",
    "# df- наш dataframe\n",
    "# n_col - количество столбцов графиков\n",
    "\n",
    "def drawing_graphs_boxplot(df, n_col):\n",
    "    m = df.shape[1] \n",
    "    i = 0\n",
    "    fig, axes = plt.subplots(1, n_col, figsize=(12, 2))\n",
    "    for column in df.columns:\n",
    "        sns.boxplot(data=df, x=column, ax=axes[i])\n",
    "        i = i + 1\n",
    "        if i > (n_col - 1) or column == df.columns[m - 1]:\n",
    "            plt.show()\n",
    "            fig, axes = plt.subplots(1, n_col, figsize=(12, 2))\n",
    "            i = 0\n",
    "    return                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c0fb1f-b2c6-4a19-ba6d-9a08e6f54e85",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs_boxplot(data_clean, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1a51dd-b4ae-41de-8473-63743a2dd2b2",
   "metadata": {},
   "source": [
    "У нас в 2-х столбцах наблюаются выбросы после замены 'подозрительных значений' СПРАВА на средние значения +/- 5 значений в столбце и очистки стандартными методами IQR и Z-C.\n",
    "Проведем дополнительную очистку  в столбцах: 'elasticity_module_stretching' и 'strapery_strength'.\n",
    "Используем функцию \"Методом подбора коэффициентов в df_min_max\" и удалением этих выбросов в df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9562882a-c333-4dd0-98db-b06510162f9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проведем иттерацию по удалению строк из нашего df со значениями в df_min_max  при max- строка '1'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370575b-4b13-4109-a4af-f51e3bd26ca4",
   "metadata": {},
   "source": [
    "Проведем очистку каждого парметра от значений  'max' лежащих дальше чем 3 СИГМА  'elasticity_module_stretching' и 'strapery_strength'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2c618-6861-4e17-8c9b-82d96843ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция очистки значений в стлбцах СПРАВА\n",
    "# пердаваемые параметры:\n",
    "# df - наш массив\n",
    "# df_min_max - массив экпертных крайних сначений для каждого столбца\n",
    "# df_name_column - массив наименований столбцов ,в которых необходимо провести очистку СПРАВА\n",
    "\n",
    "def clean_column_rigth(df, df_min_max, df_name_column):\n",
    "    sum_del_rigth = 0 # Количество строк удаленных выбросов СПРАВА после определения столбцов с выбросами в boxplot\n",
    "    # df_name_column = pd.DataFrame(columns=list_name_column)\n",
    "    for name_col in df_name_column.columns:\n",
    "        for column in df.columns:\n",
    "            if column != name_col:\n",
    "                continue\n",
    "            l_begin = len(df)\n",
    "            df = df[(df[column] < df_min_max.loc[1, column])]     \n",
    "            l_end = len(df)\n",
    "            list_x = l_begin - l_end\n",
    "            print(df.shape)\n",
    "            print('Количество подозрительных строк в столбце = ', list_x)\n",
    "            print('---------------------------------')\n",
    "        sum_del_rigth = sum_del_rigth + list_x\n",
    "    print('Общее количество удалнных подозрительных строк из-за выбросов справа в df = ', sum_del_rigth)\n",
    "    #data_clean = data_clean_def  \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe6c8dc-8c60-4fd6-a9a9-aadc6603183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим список столбцов и df, где есть выбросы СПРАВА для передачи в  функцию clean_column_rigth\n",
    "list_name_column = ['elasticity_module_stretching', 'strapery_strength']\n",
    "df_name_column = pd.DataFrame(columns=list_name_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07607ee4-4e7f-4674-a18a-f5f4d64963bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = clean_column_rigth(data_clean, df_min_max, df_name_column)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c46af12-dec7-4d83-bed2-9848c7e21405",
   "metadata": {},
   "source": [
    "Удалили 11 строк с выбросами справа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187c30d-5296-4b98-a999-f546f89eb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество строк до очистки df: ', len(data_composite_inspect))\n",
    "print('Количество строк после очистки: ', len(data_clean))\n",
    "print('Удалено строк :', (len(data_composite_inspect) - len(data_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bc0ee-c91f-47fc-89fd-238394a99fd8",
   "metadata": {},
   "source": [
    "В начальном DF  у нас было 1023 строки, сейчас осталось 951 строк. Всего удалили  72 строк на данной иттерации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ed2f7-90e4-4cc8-83af-4fa0fa23fbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Опять проверим на выбросы наш df  на примере графиков 'ящиков с усами' для каждого столбца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707c7ae-7e9b-4855-aefd-521ffe31fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_graphs_boxplot(data_clean, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a562f24-8c8c-4b5b-af8e-71255fb9f9f9",
   "metadata": {},
   "source": [
    "В нашем df опять появились выбросы после удаления 11 из-за выбросов СПРАВА по функции clean_column_rigth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62907ad8-aa7b-46e0-bd42-26e97b53d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame 'df_min_max' который содержит мин и мах значения по каждому столбу в качестве критерия отбрасывания строк \n",
    "# min - индекс сроки 0 и max- индекс строки 1 получены оценочным путем при исследовании гистограмм по каждому параметру-столбцу\n",
    "# Изменим значение в df_min_max в столбце  'elasticity_module' :[50.0, 1560.0] на значения 'elasticity_module' :[50.0, 1550.0]\n",
    "\n",
    "df_min_max =  df_min_max.replace({'elasticity_module' : { 50.0 : 50.0, 1560.0 : 1550.0}})\n",
    "df_min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce4d49-1bb2-4b23-85a5-e26939ab4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следующая иттерация по удалению выбросов СПРАВА \n",
    "# Список столбцов, где есть выбросы СПРАВА для передачи в  функцию clean_column_rigth\n",
    "list_name_column = ['elasticity_module']\n",
    "df_name_column = pd.DataFrame(columns=list_name_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee2717-9054-4278-adb5-9608794af0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторно вызываем функцию clean_column_rigth\n",
    "data_clean = clean_column_rigth(data_clean, df_min_max, df_name_column)\n",
    "data_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34363550-57df-4ed2-8c74-b62dcf2c8f39",
   "metadata": {},
   "source": [
    "В столбце 'elasticity_module' удалили еще 3 строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3597272d-8988-41c4-9aca-e326d5f58131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проведем еще одну иттерацию проврки df с  помощью boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ac4ea-2287-41b7-9f45-68a807bd8aa7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "drawing_graphs_boxplot(data_clean, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1b20b-9f14-47f3-8990-b41303334693",
   "metadata": {},
   "source": [
    "# У нас получились \"чистые \", без выброов \"ящики с усами\"!\n",
    "Перейдем к следующему этапу исследования нашего datafrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a42113-bbe2-4756-88ae-f58a70c6d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Количество строк до очистки df: ', len(data_composite_inspect))\n",
    "print('Количество строк после очистки: ', len(data_clean))\n",
    "print('Удалено строк :', (len(data_composite_inspect) - len(data_clean)))\n",
    "total_del_percent = ((len(data_composite_inspect) - len(data_clean)) / len(data_composite_inspect)) * 100\n",
    "print('Удалено : ', total_del_percent, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0610a741-b8b3-43d4-b6fe-fac53d2d1b9b",
   "metadata": {},
   "source": [
    "В начальном DF  у нас было 1023 строки, сейчас осталось 948 строк. Всего удалили  75 строк или 7.33 %."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4324312-ebce-4287-8092-3f05474674b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Запишим data_clean в новый файл 'data_main.csv' для дальнейшей работы и передачи в pipline и изучением методами sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85edc49-d271-4f1d-b2bc-72f92eb1aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запишим data_clean в новый файл 'data_main.csv' для дальнейшей работы и передачи в pipline и изучением методами sklearn\n",
    "# В массиве 'data_main.csv' мы:\n",
    "# 1. Заменили нулевые значения '0.0' в строке 19 столбцов 'Шаг нашивки' - 'step_strip'\n",
    "# и 'Плотность нашивки' - 'density_strip'\n",
    "# 2.Удалили параметр 'Угол нашивки' - 'pattern_angle' как не несущий существенной информации , так как там всего 2 значения угла  и 90 град распределенных по 50% \n",
    "# 3. Провели очистку выбросов методом IQR  и удалили еще 76 строк.\n",
    "# 4. Метод  Z - Score не нашел дополнительные выбросы\n",
    "# 5. Проведя графический аналих по boxpot,  мы убедились что в ряде столбцов остались выбросы. Чтобы убрать оставшиеся выбросы,\n",
    "#  мы в ручном режиме в цикле убрали по шаблону df_min_max значния меньше МИН и больше МАХ . Всего еще 21 строку.\n",
    "# Всего мы удалили 1023 - 941 = 82 строк  или 8 % из исходного файла \n",
    "# Считаем, что df очищен от выбросов\n",
    "\n",
    "data_clean.to_csv('data_main.csv', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a709e42-5687-4ffa-be3d-e3391f6b7516",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Этап 4 Нормализуем и стандартизируем наш dataset, чтобы привести наши данные к близким размерностям"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ce385-636c-4c52-83ce-d2820b17a05d",
   "metadata": {},
   "source": [
    "# В нашем DataSet \"data_composite_inspect\" есть 12 признаков- столбцов\n",
    "Но все признаки имеют разную размерность.\n",
    "Нормализуем и стандартизируем  наш массив \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b704692-cffb-4051-92a0-3371c59f67fd",
   "metadata": {},
   "source": [
    "# Этап 4.1 Нормализация по методу MinMaxskaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0767b77-e28f-4303-9fe7-ef2fd895e0d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# список наших столбцов\n",
    "list_data = list(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af30134a-1408-41df-bf0c-6d17fd5a436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax_scaler = MinMaxScaler() # вызываем метод MinMaxskaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283cae99-44d7-47e1-a2fa-a8d48389ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  обучаем MinMaxScaler() -передаем только числовые значения столбцов  ,указанных списком list_data или можно перечислить какие нужны\n",
    "data_clean_norm = minmax_scaler.fit_transform(np.array(data_clean[list_data])) \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be985c0-8672-4574-ae89-91f1630ae44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_norm[:1] # Проверим первую строку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c73e3-ff17-4b60-87ba-aa4c3f77d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый df с нормализованными данными с названием наших столбцов \n",
    "data_clean_norm_df = pd.DataFrame(data = data_clean_norm, columns = list_data)\n",
    "data_clean_norm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7cd34c-d2b9-4dbe-a831-7c6f085d1ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_norm_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff503da-5a93-4fcc-836d-d59b5415347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_norm_df.to_csv('data_main_norm.csv', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e49338-d7f4-4cd5-b451-dce8d8259921",
   "metadata": {},
   "source": [
    "# 4.2 Проведем стандартизацию по методу StandardSckaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88208abd-c6b9-4bbf-ae48-7bd9dd84302b",
   "metadata": {},
   "source": [
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e2ceb4-833f-4b6a-8d8a-bf43a299e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_skaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df44d8-f97e-4b05-8047-f7a1b7aaf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  обучаем StandartSkaler() - передаем только числовые значения столбцов  ,указанных списком list_data или можно перечислить какие нужны\n",
    "data_clean_std = std_skaler.fit_transform(np.array(data_clean[list_data])) \n",
    "                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbe99d-73fc-4c11-b23e-5a5c808fd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_std[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b7cbd-cff0-4283-82d0-e9d279cd7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый df со стандартизованными данными с названием наших столбцов  (вернем их)\n",
    "data_clean_std_df = pd.DataFrame(data = data_clean_std, columns = list_data)\n",
    "data_clean_std_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad857c-a1fd-4123-bb5c-cb9cc939b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_std_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d6101-4603-4199-bcba-aa191011a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_std_df.to_csv('data_main_std.csv', index=False, float_format=\"%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4143d6-0da2-484b-8fa4-cd77c4cc6c03",
   "metadata": {},
   "source": [
    "sns.displot(data =data_composite_inspect) #, kind = 'kde', fill = True) # = bin_s # hue=\"cut\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62e34a-59a2-4858-90fd-7c30cdd66f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# примеры\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

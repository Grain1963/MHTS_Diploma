{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a09d8aa-8f6f-4704-bbb8-5678e53156fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Проверка гипотезы по автоатизации проверки данных DataSet на предмет \"подозрительных\" выбросов занчений данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a03f7-fbd7-47b5-a187-004658fd7d8a",
   "metadata": {},
   "source": [
    " Мы провели графический анализ данных (см. Diploma_1). Исследование  данных в столбцах по типу box-and-wisker plot (ящик с усами) наглядно поазывают ,что в ряде столбцов ,таких как:\n",
    "Шаг нашивки                       \n",
    "Плотность нашивки                 \n",
    "модуль упругости, ГПа            \n",
    "Количество отвердителя, м.%     \n",
    "Поверхностная плотность, г/м2   \n",
    "Потребление смолы, г/м2\n",
    "имеются выбросы как в минимальной области (даже включя ноль, либо значения близкие к нулю - что противоречит физическим принципам)\n",
    "Либо значения на порядок, а то и на 3 поядка меньше медианы данных конкретного столбца так  и в максимальной области.\n",
    "\n",
    "Для принятия решения по изменению конкретных данных (замена на медиану или на умножение на конкретный коэффициент) или удалению конкретной строки данных в случае сильной флуктуации данных в строке принимаем гипотезу по созданию матрицы \"подозрительных данных\" для дальнейшей аналиа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bde4aa5-b642-4bf6-a154-fea5a8f58178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем в проект требуемые библиотеки\n",
    "\n",
    "import seaborn as sns # библиотека для создания статистических графиков\n",
    "import random #  генераторатор случайных чисел и данных\n",
    "import pandas as pd # библиотека для обработки и анализа данных\n",
    "import os # библиотека функций для работы с операционной системой.\n",
    "import numpy as np\n",
    "import tensorflow as tf # фреймворк для глубокого машинного обучения\n",
    "import csv\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.express as px\n",
    "#from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99464f7-98d8-4ec1-b404-78069edd33aa",
   "metadata": {},
   "source": [
    "# Создадим матрицу(массив) \"подозрительных данных\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d908e-34a5-427f-8500-afa7f852f113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# теперь прочитаем наш файл формата hw_data_composite_new.CSV в  котором будем изменять часть данных в определенных строках\n",
    "\n",
    "hw_data_composite_analyzis = pd.read_csv(r'C:\\Users\\grain\\Work_folder\\Diplom_MGTU\\hw_data_composite_new.csv')\n",
    "hw_data_composite_analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f84dea5-57a1-4167-830e-299ea8635038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод .describe() к количественным признакам\n",
    "hw_data_composite_analyzis.describe(percentiles = [0.25, 0.5, 0.75, 0.99], include='all').round(3) # дополнительно выводим еще одну квартилю 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1b1d65-4458-4144-be7a-8030ba82954c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hw_data_composite_analyzis.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8134f89-12a3-4ee2-9afe-bb10b19e65a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_data_composite_analyzis.loc[20][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba890f7c-befe-46f9-8f71-135b6098a1a0",
   "metadata": {},
   "source": [
    "# замечание - в  строке с индексом 19 в столбце 'Шаг нашивки' и 'Плотность нашивки' есть значения '0.0'.\n",
    "нам необходимо провести анализ и найти 'подозрительного значения'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b3bb4-9486-4714-9234-74861111ca54",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Заметим, что '50% процентиль' тоже, что и медиана!!!\n",
    "Источник - https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f401b-7575-4152-91e7-e41e448192d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Вычислим список медиан по всем столбцам - это процентиль 50%\n",
    "\n",
    "median_composit = hw_data_composite_analyzis.describe(include='all').loc['50%']\n",
    "median_composit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4fe08e-552e-4d9d-8c20-3b52cc2c01d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создадим DataFrame 'median_set' из названий столбцов и значений медиан столбцов\n",
    "# Источник - https://stackoverflow.com/questions/26097916/convert-pandas-series-to-dataframe\n",
    "\n",
    "#median_set = pd.DataFrame({'Сolumns':median_composit.index, '50%-median ':median_composit.values})\n",
    "#median_set # выводим на печать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b4ca1c-b3af-406f-8c6a-db74c34c502f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# df_zeros = pd.DataFrame(hw_data_composite_analyzis.applymap(lambda x: 0.0))  # создаем df заполненый 'o.o'  с данными типа float64\n",
    "#df_zeros = df_zeros.astype(np.float32)               # меняем тип данных  массива на float32\n",
    "#df_zeros.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d692a2-4c1e-4dec-b11f-ff0455896f92",
   "metadata": {},
   "source": [
    "# new_row_median = hw_data_composite_analyzis.median(axis=0) # параметры новой строки в конце массива - это медианы столбцов!!\n",
    "\n",
    "# df_zeros.append(new_row_median, ignore_index = True) # создаем новую строку медиан в конце массива # работает , строка добавляется\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4facb-7afe-4ec5-82a0-02c5c49c7a0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# значение критериев 'min_data'  - все значения меньше 10% от медианы- 'подозрительного значения'\n",
    "# значение критериев 'max_data'  - все значения больше медианы в 10 раз  - 'подозрительного значения'\n",
    "min_data = 0.1\n",
    "max_data = 10.0\n",
    " \n",
    "# переводим список медиан в DataFrame\n",
    "# df_median = pd.DataFrame({'Сolumns':median_composit.index, '50%-median ':median_composit.values}) \n",
    "\n",
    "for column in hw_data_composite_analyzis.columns: #\n",
    "    for i in range(len(hw_data_composite_analyzis)):\n",
    "        \n",
    "        value = hw_data_composite_analyzis.at[i,column] # значение из df -  hw_data_composite_analyzis ВАЖНО присвоение .at[i,column]\n",
    "        min_median = min_data * median_composit[column] # значение критерия 'min_median' = критерий min * медиану столбца\n",
    "        max_median = max_data * median_composit[column] # значение критерия 'mvax_median' = критерий max * медиану столбца\n",
    "               \n",
    "        if value < min_median  or value > max_median: # условие применения критериев\n",
    "            df_zeros.at[i,column] = value  # запись 'подозрительного значения' в соотвествующую ячейку нолевой матрицы df_zeros\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f74557-6a73-4a55-ada9-d9caa58efbd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создадим строку медиан из hw_data_composite_analyzis и добавим ее в конце массива df_zeros!!!#new_row_median = hw_data_composite_analyzis.median(axis=0) # параметры новой строк в конце массива!!\n",
    "#df_zeros.append(new_row_median, ignore_index = True) # создаем новую строку медиан\n",
    "\n",
    "# df2 = pd.DataFrame([[2,3,4]], columns=['A','B','C']) # Другой метод добавления строки создание df медианн и concat! \n",
    "# pd.concat([df2, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090c0fa-6cc3-4eff-a837-4c017c191f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_dataset(df, min_data, max_data, median_composit):\n",
    "# Функция analyzis_dataset создает массив 'подозрительных значений' в матрице заполненой нулями df_zeros\n",
    "# Передем в функцию:\n",
    "# df который будем исследовать\n",
    "# min_data - минимальный коэффициент отсечки для выбросов значений \"слева\"\n",
    "# max_data - максимальный коэффициент отсечки для выбросов значений \"справа\"\n",
    "# значение критериев 'min_data'  - все значения меньше 10% от медианы- 'подозрительного значения'\n",
    "# значение критериев 'max_data'  - все значения больше медианы в 10 раз  - 'подозрительного значения'\n",
    "# принимаем min_data = 0.1\n",
    "#           max_data = 10.0\n",
    "# median_composit - список median массива df рассчитан ранее в программе\n",
    "\n",
    "# создаем df_zero заполненый 'o.o'  размерности  df ( по умолчанию - с данными типа float64)\n",
    "    df_zeros = pd.DataFrame(df.applymap(lambda x: 0.0)) \n",
    "    df_zeros = df_zeros.astype(np.float32)               # меняем тип данных  массива на float32\n",
    "\n",
    "    for column in df.columns: # иттерация по столбцам\n",
    "        for i in range(len(df)): # иттерация по строкам\n",
    "            \n",
    "            value = df.at[i,column] # значение из df -  hw_data_composite_analyzis ВАЖНО писвоение .at[i,column]\n",
    "        \n",
    "            min_median = min_data * median_composit[column] # значение критерия 'min_median' = критерий min * медиану столбца\n",
    "            max_median = max_data * median_composit[column] # значение критерия 'mvax_median' = критерий max * медиану столбца\n",
    "               \n",
    "            if value < min_median  or value > max_median: # условие применения критериев\n",
    "                \n",
    "                df_zeros.at[i,column] = value  # запись 'подозрительного значения' в соотвествующую ячейку нолевой матрицы df_zeros  \n",
    "                \n",
    "                if value == 0.0:\n",
    "                    df_zeros.at[i,column] = 0.1\n",
    "\n",
    "    return df_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0665c84-76dc-4cbf-b184-26c27c9a2509",
   "metadata": {},
   "source": [
    "# Необходимо создать  отдельный модуль - функцию для проверки нашего DataSet 'hw_data_composite_analyzis' на 'подозрительные значения' и создание массива 'подозрительных значений'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de65a32-70d8-4f55-8813-7d3b00591f92",
   "metadata": {
    "tags": []
   },
   "source": [
    "# проверка функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aadf09-31da-470b-a166-5b97ac1cba76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zeros = analysis_dataset(hw_data_composite_analyzis, 0.1, 10, median_composit)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce3210-4285-4c49-ad12-247f143a04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9570a40-91bc-48ea-8388-af0e5f9f522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros = df_zeros.astype(np.float32) # опять приводим размерность данных к типу float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2cf407-9d38-40b5-aad3-33f4856a7826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dba793d-a22f-4115-a312-ea9aecefc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros.head(21).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a532f-6737-43bb-85af-fd2851a7fafb",
   "metadata": {},
   "source": [
    "# Рассчитаем количество строк в которых есть 'подозрительные значения' в массиве df_zeros.\n",
    "Создадим массив строк df_analiz используя массив df_zeros, сохранив их оригинальные индексы в отдельном столбце и введя особый столбец с указнием количества 'подозрительных значений'\n",
    "Если в какой-то строке будет больше 1 'подозрительноо значения', то  скорее всего мы будем удалять эту строку в нашем рабочем файле hw_data_composite_analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19941e-d9cb-4efe-93ff-8ecb48ba3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новый  df_analiz_id для вывода индексов строк  'подозрительных значений'  с одной строкой с нулевыми значениями \n",
    "# (далее будем добавлять строки по мере возникнвения новых строк с ощибками) .\n",
    "\n",
    "df_analis_id = pd.DataFrame(columns=('Индекс строки исходного DataSet', 'Колиества ошибок в строке'))\n",
    "#df_analis = pd.DataFrame(columns=df_zeros.columns) # передали в новый df наиенования старых толбцов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ba949-ffc1-4c73-af85-afdfeceb2e63",
   "metadata": {
    "tags": []
   },
   "source": [
    "# теперь добавим в df_analiz 2 новых  столбца: 'Индекс старого массива', 'Колиества ошибок в строке'\n",
    "#df_analis.insert (loc = 0, column='Колиества ошибок в строке', value= False) # вставляем певую колонку вначале таблицы\n",
    "#df_analis.insert (loc = 0, column='Индекс старого массива', value= False) # вставляем  колонку на первое место\n",
    "#df_analis.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2426c-e776-4a0e-9394-aee7fb668b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_id.shape #  у нас получилась таблица на 2 столбцов и пока 0 строки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a4cac-bd37-4f07-87de-7942667c12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b70307-dbe5-48a9-96e1-69439bbc3c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_analis_id.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478a578-292e-458d-9154-3553553f9146",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_bugs = pd.DataFrame(columns=df_zeros.columns) # передали в созданый новый df наиенования старых толбцов, но у нс 0 строк\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008f321-e56b-4c5b-88d7-aedcfe7b8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_bugs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297708c-e4e2-43d1-8daf-20adb878f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_bugs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc65abb2-2c69-451b-b69f-b92b8328bc1f",
   "metadata": {},
   "source": [
    "# Добавим строку  состоящую из 0.0\n",
    "df_analis_bugs.loc[len(df_analis_bugs.index)]= [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e7bbf0-1313-4d35-80f2-686452f0ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_analis_bugs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67859c9-c518-4739-8fba-b022caee5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d55476-c724-4e9f-9236-8031110f6158",
   "metadata": {},
   "source": [
    "#df_analis_bugs = df_analis_bugs.astype(np.float32) # приводим размерность данных к типу float32\n",
    "#df_analis_bugs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb895d-ed3a-4c26-9658-786172e892a1",
   "metadata": {},
   "source": [
    "ПРОВЕРИТЬ!!!\n",
    "# df_analis_id = df_analis_id.astype(np.Int32) # приводим размерность данных к типу int32\n",
    "# df_analis_id.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9704f634-2e1d-4108-83b3-e5ce1a84a2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Подсчитаем в каждой строке матрицы количество 'подозрительных значений' - df_zeros и будем записывать\n",
    "# в создаваемую строку j  матрицы df_analis_bugs:\n",
    "# а также запишем в два  столбца df_analis_id в создаваемую строку j получаемые результаты:\n",
    "# индекс строки  cтарого массива df_zeros, количества ошибок coun_bug_row в соотвествующем столбце\n",
    "\n",
    "new_id = 0             # индекс первой строк массива df_analis_id и df_analis_bugs\n",
    "\n",
    "for i in range(len(df_zeros)):      # len(df_zeros) -это количество строк -1023\n",
    "    \n",
    "    count_bug_row = 0               # количества ошибок count_bug_row в строке 'i' массива df_zeros\n",
    "    \n",
    "    \n",
    "    for column in df_zeros.columns:\n",
    "      \n",
    "        if df_zeros.loc[i, column] != 0.0 and count_bug_row == 0:  # .at\n",
    "            \n",
    "            # Добавим строку  состоящую из 0.0\n",
    "            df_analis_bugs.loc[len(df_analis_bugs.index)]= [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "            new_row = {'Индекс строки исходного DataSet':[0],'Колиества ошибок в строке':[0]}\n",
    "            df_analis_id =  df_analis_id.append(new_row, ignore_index=True)\n",
    "        df = pd.concat([df, new_df], axis=0, ignore_index=True)\n",
    "       \n",
    "    \n",
    "        elif  df_zeros.loc[i, column] != 0.0:    \n",
    "            print('new_id', new_id, 'i  ', i, 'column', column)  # работает \n",
    "            print('------' )           \n",
    "            df_analis_id.at[new_id, 0] = i  # работает !! # записываем в столбец \"Индекс старого массива\" номер старого индекса строки, чтобы можно было найти в основном файлене !!нужено ПРОВЕРИТЬ!!!    \n",
    "            \n",
    "            print(df_analis_id.at[new_id, 0]) # получается float??? работает\n",
    "            \n",
    "            value1 = df_zeros.at[i,column] # записываем значение ячейки в переменную value1 РАБОТАЕТ\n",
    "            print('value1',df_zeros.at[i,column])\n",
    "            print('Мммм------' )     \n",
    "            df_analis_bugs.at[new_id, column] = value1 #  записываем 'подозрительное значение' в cотвествующий столбец параметра \n",
    "            \n",
    "            print('номер нового индекса new_id = ', new_id, end='\\n')\n",
    "            print('номер старого индекса  i =', i, column)\n",
    "            print('ЦЦЦЦЦЦ------' )\n",
    "  \n",
    "            count_bug_row = count_bug_row + 1 #.at\n",
    "            df_analis_id.loc[new_id, 1] = count_bug_row # записываем колчество 'подозрительных значений' в столбец 'количество bugs' старого индекса  i = проверяемой строке\n",
    "            print('количество bugs',  df_analis_id.loc[new_id, 1])\n",
    "            print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX') \n",
    "    #print('Конец цикла XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')     \n",
    "        # добавляем новую строку в df_analis_bugs и df_analis_id\n",
    "   \n",
    "   # df_analis_id.loc[len(df_analis_id.index)] = [0.0, 0.0]\n",
    "    \n",
    "        #print('количество bugs', count_bug_row, end='\\n')\n",
    "        #print('________________________')\n",
    "    \n",
    "   # j = j + 1        \n",
    "           \n",
    "# df_analis.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7adb69-c9a7-437d-916c-4afe55becbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff1255-f1bc-4b33-8052-38a8847d19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analis_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c70d8-e668-4131-af6c-a531d2344929",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.drop_duplicates() убираем дубликаты если есть, но сначала делаем сопию файла и уже убираем дубликаты из копии, не затрагивая основной файл"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbb037-6835-497e-bbda-119932b3d8e4",
   "metadata": {},
   "source": [
    "Использование inplace=True изменит исходный объект DataFrame:\n",
    "Еще один важный аргумент drop_duplicates() — keep, который имеет три возможных опции:\n",
    "\n",
    "first: Отбросить дубликаты, кроме первого вхождения (опция по умолчанию).\n",
    "last: Отбросить дубликаты, кроме последнего вхождения.\n",
    "False: Отбросить все дубликаты.\n",
    "Поскольку в предыдущем примере мы не определили аргумент keep, он был задан по умолчанию как first. Это означает, что если две строки одинаковы, pandas отбросит вторую и сохранит первую. Использование last имеет противоположный эффект: отбрасывается первая строка.\n",
    "\n",
    "А вот keep=False отбрасывает все дубликаты. Если две строки одинаковы, то обе будут отброшены. Посмотрите, что произойдет с temp_df:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24704d2-eabe-4464-a614-2506f91a7a28",
   "metadata": {},
   "source": [
    "Мы можем использовать метод .rename() для переименования определенных или всех столбцов с помощью словаря. Нам не нужны круглые скобки, поэтому давайте избавимся от них:\n",
    "\n",
    "!!!Если вы будете работать с набором данных в течение некоторого времени, рекомендуется использовать нижний регистр, удалить специальные символы и заменить пробелы символами подчеркивания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21676853-9438-4fbb-9e7a-6a962d391fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31b538-9d42-4feb-8dbb-f9089d12e790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361f1d8-5e8a-4fc0-a507-96ead6f63aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea7422-cc7f-4e5f-86e8-173d8cac8da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

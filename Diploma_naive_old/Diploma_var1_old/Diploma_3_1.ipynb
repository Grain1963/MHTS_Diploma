{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b41e51-4094-466e-90d4-26094d9215f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad171675-f1c3-4b09-b287-c1b6187d03dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Проверка гипотезы по автоатизации проверки данных DataSet на предмет \"подозрительных\" выбросов занчений данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85b23b7-b367-4cd9-8847-86aae7d1efa2",
   "metadata": {},
   "source": [
    " Мы провели графический анализ данных (см. Diploma_1). Исследование  данных в столбцах по типу box-and-wisker plot (ящик с усами) наглядно поазывают ,что в ряде столбцов ,таких как:\n",
    "Шаг нашивки                       \n",
    "Плотность нашивки                 \n",
    "модуль упругости, ГПа            \n",
    "Количество отвердителя, м.%     \n",
    "Поверхностная плотность, г/м2   \n",
    "Потребление смолы, г/м2\n",
    "имеются выбросы как в минимальной области (даже включя ноль, либо значения близкие к нулю - что противоречит физическим принципам)\n",
    "Либо значения на порядок, а то и на 3 поядка меньше медианы данных конкретного столбца так  и в максимальной области.\n",
    "\n",
    "Для принятия решения по изменению конкретных данных (замена на медиану или на умножение на конкретный коэффициент) или удалению конкретной строки данных в случае сильной флуктуации данных в строке принимаем гипотезу по созданию матрицы \"подозрительных данных\" для дальнейшей аналиа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492d373-9d1c-4f76-9ad5-41587eecd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем в проект требуемые библиотеки\n",
    "\n",
    "import seaborn as sns # библиотека для создания статистических графиков\n",
    "import random #  генераторатор случайных чисел и данных\n",
    "import pandas as pd # библиотека для обработки и анализа данных\n",
    "import os # библиотека функций для работы с операционной системой.\n",
    "import numpy as np\n",
    "import tensorflow as tf # фреймворк для глубокого машинного обучения\n",
    "import csv\n",
    "#import matplotlib.pyplot as plt\n",
    "#from matplotlib import cm\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#import plotly\n",
    "#import plotly.graph_objs as go\n",
    "#import plotly.express as px\n",
    "#from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ddd5b-a84d-403a-aa75-abbc7b5562a1",
   "metadata": {},
   "source": [
    "# Создадим матрицу(массив) \"подозрительных данных\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d753c54-85de-48f2-b5d5-2591c22ebed8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# теперь прочитаем наш файл формата hw_data_composite_new.CSV в  котором будем изменять часть данных в определенных строках\n",
    "\n",
    "hw_data_composite_analyzis = pd.read_csv(r'C:\\Users\\grain\\Work_folder\\Diplom_MGTU\\hw_data_composite_new.csv')\n",
    "hw_data_composite_analyzis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f9662-8be2-4e2f-af87-68e23254337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим метод .describe() к количественным признакам\n",
    "hw_data_composite_analyzis.describe(percentiles = [0.25, 0.5, 0.75, 0.99], include='all').round(3) # дополнительно выводим еще одну квартилю 99%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230eab05-5180-4d17-85a4-5c7fa2362c3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Проверим наш DataFrame на наличие дубликатов  строк "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60619e0-918e-4d12-9093-67c6779f659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_data_composite_analyzis_del = hw_data_composite_analyzis.loc[:,~hw_data_composite_analyzis.apply(lambda x: x.duplicated(),axis=1).all()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbd8a8-f8a8-4068-9664-1cefe848f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw_data_composite_analyzis_del.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e0677-9c60-4d00-b4a6-7216072cf438",
   "metadata": {},
   "source": [
    "# В нашем dataFrame НЕТ дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3a327-5185-4fe4-bc4b-d645fe6f187f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hw_data_composite_analyzis.head(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f15d0d-ee86-4890-985f-7759edbfa8c8",
   "metadata": {},
   "source": [
    "# замечание - в  строке с индексом 19 в столбце 'Шаг нашивки' и 'Плотность нашивки' есть значения '0.0'.\n",
    "нам необходимо провести анализ и найти 'подозрительного значения'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a9840-f959-440c-b246-098be1574400",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Заметим, что '50% процентиль' тоже, что и медиана!!!\n",
    "Источник - https://pandas.pydata.org/docs/dev/reference/api/pandas.DataFrame.describe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d42943-5d8e-4bcc-91f3-0d24b7312f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Вычислим список медиан по всем столбцам - это процентиль 50%\n",
    "\n",
    "median_composit = hw_data_composite_analyzis.describe(include='all').loc['50%']\n",
    "median_composit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a2005-a814-42f8-bdc3-ea330215df58",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Создадим DataFrame 'median_set' из названий столбцов и значений медиан столбцов\n",
    "# Источник - https://stackoverflow.com/questions/26097916/convert-pandas-series-to-dataframe\n",
    "\n",
    "#median_set = pd.DataFrame({'Сolumns':median_composit.index, '50%-median ':median_composit.values})\n",
    "#median_set # выводим на печать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52cb0b7-77ed-4b00-b92a-55f8aa1824eb",
   "metadata": {},
   "source": [
    " new_row_median = hw_data_composite_analyzis.median(axis=0) # параметры новой строки в конце массива - это медианы столбцов!!\n",
    "\n",
    " df_zeros.append(new_row_median, ignore_index = True) # создаем новую строку медиан в конце массива # работает , строка добавляется\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083dc14-97c6-4e8b-bca9-ec74ee629b66",
   "metadata": {
    "tags": []
   },
   "source": [
    " значение критериев 'min_data'  - все значения меньше 10% от медианы- 'подозрительного значения'\n",
    " значение критериев 'max_data'  - все значения больше медианы в 10 раз  - 'подозрительного значения'\n",
    "min_data = 0.1\n",
    "max_data = 10.0\n",
    " \n",
    " переводим список медиан в DataFrame\n",
    " df_median = pd.DataFrame({'Сolumns':median_composit.index, '50%-median ':median_composit.values}) \n",
    "\n",
    "for column in hw_data_composite_analyzis.columns: #\n",
    "    for i in range(len(hw_data_composite_analyzis)):\n",
    "        \n",
    "        value = hw_data_composite_analyzis.at[i,column] # значение из df -  hw_data_composite_analyzis ВАЖНО присвоение .at[i,column]\n",
    "        min_median = min_data * median_composit[column] # значение критерия 'min_median' = критерий min * медиану столбца\n",
    "        max_median = max_data * median_composit[column] # значение критерия 'mvax_median' = критерий max * медиану столбца\n",
    "               \n",
    "        if value < min_median  or value > max_median: # условие применения критериев\n",
    "            df_zeros.at[i,column] = value  # запись 'подозрительного значения' в соотвествующую ячейку нолевой матрицы df_zeros\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35942ea-86af-44e8-a252-cfb69fe78db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создадим строку медиан из hw_data_composite_analyzis и добавим ее в конце массива df_zeros!!!#new_row_median = hw_data_composite_analyzis.median(axis=0) # параметры новой строк в конце массива!!\n",
    "#df_zeros.append(new_row_median, ignore_index = True) # создаем новую строку медиан\n",
    "\n",
    " \n",
    "# pd.concat([df2, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa19c6-80a3-4a90-ab9e-a81b192e24c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_dataset(df, min_data, max_data, median_composit):\n",
    "# Функция analyzis_dataset создает массив 'подозрительных значений' в матрице заполненой NaN df_zeros\n",
    "# Передем в функцию:\n",
    "# df который будем исследовать\n",
    "# min_data - минимальный коэффициент отсечки для выбросов значений \"слева\"\n",
    "# max_data - максимальный коэффициент отсечки для выбросов значений \"справа\"\n",
    "# значение критериев 'min_data'  - все значения меньше 10% от медианы столбца - 'подозрительное значение'\n",
    "# значение критериев 'max_data'  - все значения больше медианы столбца в 10 раз  - 'подозрительное значение'\n",
    "# принимаем min_data = 0.1\n",
    "#           max_data = 10.0\n",
    "# median_composit - список median массива df рассчитан ранее в программе\n",
    " \n",
    "    list_df = list(df) # получаем список наименований столбцов из df\n",
    "    \n",
    "    # создаем df_zero заполненый 'NaN'  размерности  df (по умолчанию - с данными типа object)\n",
    "    df_zeros = pd.DataFrame(columns=list_df, index = range(0, len(df)))\n",
    "                      \n",
    "    for column in df.columns: # иттерация по столбцам\n",
    "        for i in range(len(df)): # иттерация по строкам\n",
    "            \n",
    "            value = df.at[i,column] # значение из df -  hw_data_composite_analyzis ВАЖНО писвоение .at[i,column]\n",
    "        \n",
    "            min_median = min_data * median_composit[column] # значение критерия 'min_median' = критерий min * медиану столбца\n",
    "            max_median = max_data * median_composit[column] # значение критерия 'mvax_median' = критерий max * медиану столбца\n",
    "               \n",
    "            if value < min_median  or value > max_median: # условие применения критериев\n",
    "                df_zeros.at[i,column] = value  # запись 'подозрительного значения' в соотвествующую ячейку нолевой матрицы df_zeros  \n",
    "        \n",
    "    # меняем тип данных  массива на float32                       \n",
    "    df_zeros = df_zeros.astype(np.float32)\n",
    "    \n",
    "    return df_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d65b6-1adc-449c-93eb-74217446c640",
   "metadata": {},
   "source": [
    "# Необходимо создать  отдельный модуль - функцию для проверки нашего DataSet 'hw_data_composite_analyzis' на 'подозрительные значения' и создание массива 'подозрительных значений'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090c0fa-6cc3-4eff-a837-4c017c191f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_dataset(df, min_data, max_data, median_composit):\n",
    "# Функция analyzis_dataset создает массив 'подозрительных значений' в матрице заполненой нулями df_zeros\n",
    "# Передем в функцию:\n",
    "# df который будем исследовать\n",
    "# min_data - минимальный коэффициент отсечки для выбросов значений \"слева\"\n",
    "# max_data - максимальный коэффициент отсечки для выбросов значений \"справа\"\n",
    "# значение критериев 'min_data'  - все значения меньше 10% от медианы- 'подозрительного значения'\n",
    "# значение критериев 'max_data'  - все значения больше медианы в 10 раз  - 'подозрительного значения'\n",
    "# принимаем min_data = 0.1\n",
    "#           max_data = 10.0\n",
    "# median_composit - список median массива df рассчитан ранее в программе\n",
    "\n",
    "# создаем df_zero заполненый 'NaN'  размерности  df ( по умолчанию - с данными типа float64)\n",
    "# list(df.columns) - это список наименований столбцов df (list)\n",
    "# количество строк - len(df) \n",
    "    \n",
    "    df_zeros = pd.DataFrame(columns = list(df.columns), index = range(0, len(df))) \n",
    "\n",
    "    for column in df.columns: # иттерация по столбцам\n",
    "        for i in range(len(df)): # иттерация по строкам\n",
    "            \n",
    "            value = df.at[i,column] # значение из df -  hw_data_composite_analyzis ВАЖНО писвоение .at[i,column]\n",
    "        \n",
    "            min_median = min_data * median_composit[column] # значение критерия 'min_median' = критерий min * медиану столбца\n",
    "            max_median = max_data * median_composit[column] # значение критерия 'mvax_median' = критерий max * медиану столбца\n",
    "               \n",
    "            if value < min_median  or value > max_median: # условие применения критериев\n",
    "                df_zeros.at[i,column] = value  # запись 'подозрительного значения' в соотвествующую ячейку нолевой матрицы df_zeros  \n",
    "                \n",
    "    df_zeros = df_zeros.astype(np.float32)\n",
    "    return df_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8717286f-4033-4bea-995e-f5def38fee81",
   "metadata": {
    "tags": []
   },
   "source": [
    "# проверка функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2559ca3-a5c5-491d-abed-cf39e11a9dbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zeros = analysis_dataset(hw_data_composite_analyzis, 0.1, 10, median_composit)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5798aac-61d7-4a76-a6d0-0c02ceb79f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436c001-bee7-47de-9ea7-9454599281bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zeros.head(21).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0043c0-da6b-4ac1-b4a6-a0740388dbf0",
   "metadata": {
    "tags": []
   },
   "source": [
    "как видим в строке с индексом 19 в первом и втором столбцах появились значения- маркеры- 0.01 - значит в этих ячейках были аномальные значения '0.0'. в других строках в других таблицах также стоят значения отличающиеся от ьедианы столбца. Например в строке 104 в столбце \"модуль упругости, ГПа\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae45c2d-4d66-4d34-ad58-277ce0904896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zeros.iloc[100:110, 1 : 12].round(3) # !!! вывод необходимых строк"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae22a9-d5ef-49c2-aea6-3f6139336603",
   "metadata": {},
   "source": [
    "# у нас программа нашла, для примера 'подоззрительное значение' в строке 109 столбец 'модуль упругости, ГПа' = 9.986\n",
    "и в строке 109 столбца 'Поверхностная плотность, г/м2' = 12.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafa1eda-0fa8-4796-8a66-1423c3fe4742",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zeros.nunique(axis= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96589cf9-082f-4b1f-88f9-f5ae622b129b",
   "metadata": {},
   "source": [
    "# Судя по данным .nunique(axis= 0) у нас всего 70 подозрительных значений в 4 колонках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349648b-7ded-4cb1-b49a-1c54edb9f25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# копируем df_zeros с ошибками в новый df и будем работать дальше с df_zeros_dropNaN\n",
    "df_zeros_dropNaN = df_zeros.copy()\n",
    "df_zeros_dropNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f97501-65b2-4392-a9c7-4dd9e7147500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Удаляем все строки в которых содержаться исключительно значения NaN\n",
    "# Мы получим df_analises в котором индексы укажут на строки в которых есть bugs!!!!!\n",
    "\n",
    "df_analises = df_zeros_dropNaN.dropna(axis=0, how='all')\n",
    "\n",
    "df_analises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27159195-3e63-4beb-904d-b551c7effe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analises.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c06659-f229-471a-b21b-05eaf103b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем столбцы , где все значения NaN\n",
    "df_analises.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70081bb-7543-4354-acf0-81ef0ee39469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# список индексов ,в которых есть  bugs. Таких строк  - 66!!!\n",
    "list_id_bugs = list(df_analises.index) \n",
    "print(list_id_bugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b335c-ac54-4258-8052-8aea7a652d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_column_bugs = list(df_analises.columns) \n",
    "list_column_bugs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62822a-360f-49c7-96f9-1a4416fc031b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Рассчитаем количество строк в которых есть 'подозрительные значения' в массиве df_zeros.\n",
    "Создадим массив строк df_analiz используя массив df_zeros, сохранив их оригинальные индексы в отдельном столбце и введя особый столбец с указнием количества 'подозрительных значений'\n",
    "Если в какой-то строке будет больше 1 'подозрительноо значения', то  скорее всего мы будем удалять эту строку в нашем рабочем файле hw_data_composite_analyzis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0b1fb-28a9-4a09-9782-fd78d745c08a",
   "metadata": {},
   "source": [
    "Мы можем использовать метод .rename() для переименования определенных или всех столбцов с помощью словаря. Нам не нужны круглые скобки, поэтому давайте избавимся от них:\n",
    "\n",
    "!!!Если вы будете работать с набором данных в течение некоторого времени, рекомендуется использовать нижний регистр, удалить специальные символы и заменить пробелы символами подчеркивания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb139e21-167f-4aaf-b2f7-6073f0b5c3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc717319-baa0-4d59-896e-837362321fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281a627-2a88-4e28-9052-76f539c974a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
